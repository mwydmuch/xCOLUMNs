{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize results for Marek's thesis\n",
    "\n",
    "This notebook is used to generate latex tables for Marek's thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_vs_top_h_table(\n",
    "    experiments,\n",
    "    base_method = \"optimal-instance-precision\",\n",
    "    table_header = \"\",\n",
    "    multiplier = 100,\n",
    "    per_page = 9,\n",
    "    top_k = 5,\n",
    "):\n",
    "    basic_methods = {\n",
    "        \"optimal-instance-precision\": \"\\\\InfTopK\",\n",
    "        \"optimal-instance-ps-precision\": \"\\\\InfPSK\",\n",
    "    }\n",
    "\n",
    "    metrics = {\n",
    "        \"instance-precision\": \"Precision\",\n",
    "        \"ps-precision\": \"Propensity-scored Prec.\",\n",
    "        \"instance-recall\": \"Recall\",\n",
    "        \"midrule\": \"\\\\midrule\",\n",
    "        \"macro-precision\": \"Macro-Precision\",\n",
    "        \"macro-recall\": \"Macro-Recall\",\n",
    "        #\"macro-balanced-accuracy\": \"BA\",\n",
    "        \"macro-f1\": \"Macro-F$_1$\",\n",
    "        #\"macro-jaccard-score\": \"JS\",\n",
    "        # \"macro-gmean\": \"GM\",\n",
    "        # \"macro-hmean\": \"HM\",\n",
    "        \"coverage\": \"Coverage\"\n",
    "    }\n",
    "\n",
    "    table = \"\"\n",
    "    for e, (experiment, experiment_label) in enumerate(experiments.items()):\n",
    "        all_results = {}\n",
    "        for top_k in [1, 3, 5]:\n",
    "            filename = f\"{experiment}/{base_method}_k={top_k}_v=0.0_s=13_results.json\"\n",
    "            if os.path.exists(filename):\n",
    "                with open(filename, \"r\") as f:\n",
    "                    result_file_data = json.load(f)\n",
    "                for metric, metric_label in metrics.items():\n",
    "                    metric = f\"{metric}@{top_k}\"\n",
    "                    if metric in result_file_data:\n",
    "                        all_results[f\"{metric}_all\"] = result_file_data[metric] * multiplier\n",
    "\n",
    "            filename = filename.replace(\"_k=\", \"_top_labels=0.2_k=\")\n",
    "            filename = filename.replace(\"org2\", \"org4\")\n",
    "            if os.path.exists(filename):\n",
    "                with open(filename, \"r\") as f:\n",
    "                    result_file_data = json.load(f)\n",
    "                for metric, metric_label in metrics.items():\n",
    "                    metric = f\"{metric}@{top_k}\"\n",
    "                    if metric in result_file_data:\n",
    "                        all_results[f\"{metric}_top\"] = result_file_data[metric] * multiplier\n",
    "        \n",
    "        print(all_results)\n",
    "        results = []\n",
    "        for metric, metric_label in metrics.items():\n",
    "            _result = {\"Metric\": metric_label}\n",
    "            for top_k in [1, 3, 5]:\n",
    "                _metric = f\"{metric}@{top_k}\"\n",
    "                _result[f\"{top_k}_all\"] = all_results.get(f\"{_metric}_all\", \"-\")\n",
    "            for top_k in [1, 3, 5]:\n",
    "                _metric = f\"{metric}@{top_k}\"\n",
    "                _ref_value = all_results.get(f\"{_metric}_all\", \"-\")\n",
    "                _value = all_results.get(f\"{_metric}_top\", \"-\")\n",
    "                _diff = None\n",
    "                if _ref_value != \"-\" and _value != \"-\":\n",
    "                    _diff = (_value - _ref_value) / _ref_value * 100\n",
    "                if _value != \"-\":\n",
    "                    _value = f\"{_value:.2f}\"\n",
    "                if _diff is not None:\n",
    "                    color = r\"\\color{green}\"\n",
    "                    if _diff < -5:\n",
    "                        color = r\"\\color{orange}\"\n",
    "                    if _diff < -30:\n",
    "                        color = r\"\\color{red}\"\n",
    "                    _diff = f\" {{\\\\scriptsize {color} ({_diff:.2f}\\\\%)}}\"\n",
    "                _result[f\"{top_k}_top\"] = _value\n",
    "                _result[f\"{top_k}_top_diff\"] = _diff\n",
    "                \n",
    "                \n",
    "            results.append(_result)\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "        \n",
    "        table += \"\\n\"\n",
    "        if e % per_page == 0:\n",
    "            if e == 0:\n",
    "                table += \"\\\\begin{table}\\n\"\n",
    "                table += table_header\n",
    "                table += \"\\\\small\\n\"\n",
    "            table += \"\"\"\n",
    "\\\\centering\n",
    "\\\\resizebox{\\\\linewidth}{!}{\n",
    "\\\\begin{tabular}{l|rrr|rlrlrl}\n",
    "\\\\toprule\n",
    "    Metric & \\\\multicolumn{3}{c|}{With all labels} & \\\\multicolumn{6}{c}{With top 20\\\\% labels} \\\\\\\\\n",
    "    & \\\\multicolumn{1}{c}{$@1$} & \\\\multicolumn{1}{c}{$@3$} & \\\\multicolumn{1}{c|}{$@5$} \n",
    "    & \\\\multicolumn{2}{c}{$@1$} & \\\\multicolumn{2}{c}{$@3$} & \\\\multicolumn{2}{c}{$@5$} \\\\\\\\\n",
    "\"\"\"\n",
    "# Metric & \\\\multicolumn{3}{c|}{Class. with all labels} & \\\\multicolumn{6}{c}{Classifier with top 20\\\\% labels} \\\\\\\\\n",
    "        table += f\"\\\\midrule\\n\"\n",
    "        table += f\"\\\\multicolumn{{10}}{{c}}{{{experiment_label}}} \\\\\\\\\\n\"\n",
    "\n",
    "        # Print the results as a latex table\n",
    "        latex_table = df.to_latex(index=False, float_format=\"{:0.2f}\".format)\n",
    "        #latex_table = df.to_latex(index=False)\n",
    "        table += \"\\n    \".join(latex_table.split(\"\\n\")[3:-3]).replace(\"\\midrule & - & - & - & - & NaN & - & NaN & - & NaN \\\\\\\\\", \"\\midrule\")\n",
    "\n",
    "        if e % per_page == per_page - 1 or e == len(experiments) - 1:\n",
    "            table += \"\"\"\n",
    "\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_exp_dir = \"results_thesis_org2\"\n",
    "\n",
    "experiments = {\n",
    "    f\"../{org_exp_dir}/rcv1x_100_plt\": \"RCV1x-2K\",\n",
    "    f\"../{org_exp_dir}/eurlex_100_plt\": \"Eurlex-4K\",\n",
    "    f\"../{org_exp_dir}/EURLex-4.3K_100_plt\": \"Eurlex-4.3K\",\n",
    "    f\"../{org_exp_dir}/amazonCat_100_plt\": \"AmazonCat-13K\",\n",
    "    f\"../{org_exp_dir}/amazonCat-14K_100_plt\": \"AmazonCat-14K\",\n",
    "    #f\"../{org_exp_dir}/wiki10_100_plt\": \"Wiki10-31K\",\n",
    "    #f\"../{org_exp_dir}/deliciousLarge_100_plt\": \"DeliciousLarge-200K\",\n",
    "    f\"../{org_exp_dir}/wikiLSHTC_100_plt\": \"WikiLSHTC-325K\",\n",
    "    f\"../{org_exp_dir}/WikipediaLarge-500K_100_plt\": \"WikipediaLarge-500K\",\n",
    "    f\"../{org_exp_dir}/amazon_100_plt\": \"Amazon-670K\",\n",
    "}\n",
    "\n",
    "header_main = r\"\"\"\n",
    "\\caption{Results (\\%) of a classifier trained on the full set of labels\n",
    "and a classifier trained with only the top 20\\% of labels (most frequent labels) \n",
    "on different metrics budgeted at $k$ ($@k$).\n",
    "}\n",
    "\\label{tab:all-vs-top-h}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"tables_thesis/results-all-vs-top-h.tex\", \"w\") as f:\n",
    "    f.write(generate_full_vs_top_h_table(experiments, table_header=header_main, per_page=9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "EPSS = [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 4e-5, 5e-5, 6e-5, 9e-5, 1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 6e-4, 1e-3, 2e-3, 5e-3, 1e-2, 2e-2, 5e-2, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3, 3e-3, 5e-3, 1e-2]\n",
    "#EPSS = [1e-8, 1e-6, 1e-4]\n",
    "TOL = 1e-7\n",
    "seeds = [13, 1988, 1993, 2023, 2024]\n",
    "seeds = [13, 1988, 1993, 2023, 2024]\n",
    "val_split = 0.0\n",
    "\n",
    "metrics = {\n",
    "    \"instance-precision\": \"P\",\n",
    "    \"ps-precision\": \"PS\",\n",
    "    \"instance-recall\": \"R\",\n",
    "    \"macro-precision\": \"P\",\n",
    "    \"macro-recall\": \"R\",\n",
    "    \"macro-balanced-accuracy\": \"BA\",\n",
    "    \"macro-f1\": \"F\",\n",
    "    \"macro-jaccard-score\": \"JS\",\n",
    "    # \"macro-gmean\": \"GM\",\n",
    "    # \"macro-hmean\": \"HM\",\n",
    "    \"coverage\": \"C\"\n",
    "}\n",
    "\n",
    "\n",
    "def generate_table_with_results(\n",
    "    experiments,\n",
    "    table_header = \"\",\n",
    "    multiplier = 100,\n",
    "    per_page = 3,\n",
    "    add_std = False,\n",
    "    top_k = 5,\n",
    "):\n",
    "    basic_methods = {\n",
    "        \"optimal-instance-precision\": \"\\\\InfTopK\",\n",
    "        \"optimal-instance-ps-precision\": \"\\\\InfPSK\",\n",
    "        \"power-law-with-beta=0.25\": \"\\\\InfPowerK$_{\\\\beta=0.25}$\",\n",
    "        \"power-law-with-beta=0.5\": \"\\\\InfPowerK$_{\\\\beta=0.5}$\",\n",
    "        #\"power-law-with-beta=0.75\": \"\\\\InfPowerK\",\n",
    "        \"log\": \"\\\\InfLogK\",\n",
    "        \"optimal-macro-recall\": \"\\\\InfMacR\",\n",
    "        \"optimal-macro-balanced-accuracy\": \"\\\\InfMacBA\",\n",
    "        \"midrule1\": \"\\\\midrule\",\n",
    "    }\n",
    "    methods = basic_methods.copy()\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"block-coord-macro-precision-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacP$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"block-coord-macro-recall-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacR$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"block-coord-macro-balanced-accuracy-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacBA$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"block-coord-macro-f1-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacF$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"block-coord-macro-jaccard-score-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacJS$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    methods.update({\n",
    "        f\"block-coord-coverage-tol={TOL}\": \"\\\\InfBCACov\",\n",
    "        \"midrule2\": \"\\\\midrule\",\n",
    "    })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"frank-wolfe-macro-precision-eps={eps}\": f\"\\\\InfFWMacP$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"frank-wolfe-macro-recall-eps={eps}\": f\"\\\\InfFWMacR$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"frank-wolfe-macro-balanced-accuracy-eps={eps}\": f\"\\\\InfFWMacBA$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"frank-wolfe-macro-f1-eps={eps}\": f\"\\\\InfFWMacF$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"frank-wolfe-macro-jaccard-score-eps={eps}\": f\"\\\\InfFWMacJS$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    # methods.update({\n",
    "    #     \"midrule3\": \"\\\\midrule\",\n",
    "    # })\n",
    "\n",
    "    # thr = 0.05\n",
    "    # methods.update({\n",
    "    #     \"optimal-instance-precision_proba_threshold={thr}\": \"\\\\InfTopK\",\n",
    "    #     \"optimal-instance-ps-precision_proba_threshold={thr}\": \"\\\\InfPSK\",\n",
    "    #     \"power-law-with-beta=0.25_proba_threshold={thr}\": \"\\\\InfPowerK$_{\\\\beta=0.25}$\",\n",
    "    #     \"power-law-with-beta=0.5_proba_threshold={thr}\": \"\\\\InfPowerK$_{\\\\beta=0.5}$\",\n",
    "    #     #\"power-law-with-beta=0.75\": \"\\\\InfPowerK\",\n",
    "    #     \"log_proba_threshold={thr}\": \"\\\\InfLogK\",\n",
    "    #     \"optimal-macro-recall_proba_threshold={thr}\": \"\\\\InfMacR\",\n",
    "    #     \"optimal-macro-balanced-accuracy_proba_threshold={thr}\": \"\\\\InfMacBA\",\n",
    "    #     \"midrule1\": \"\\\\midrule\",\n",
    "    # })\n",
    "\n",
    "    # for eps in EPSS:\n",
    "    #     methods.update({\n",
    "    #         f\"frank-wolfe-macro-precision-eps={eps}_proba_threshold={thr}\": f\"\\\\InfFWMacP$_{{\\\\epsilon={eps}}}$\",\n",
    "    #     })\n",
    "\n",
    "    # for eps in EPSS:\n",
    "    #     methods.update({\n",
    "    #         f\"frank-wolfe-macro-recall-eps={eps}_proba_threshold={thr}\": f\"\\\\InfFWMacR$_{{\\\\epsilon={eps}}}$\",\n",
    "    #     })\n",
    "\n",
    "    # for eps in EPSS:\n",
    "    #     methods.update({\n",
    "    #         f\"frank-wolfe-macro-balanced-accuracy-eps={eps}_proba_threshold={thr}\": f\"\\\\InfFWMacBA$_{{\\\\epsilon={eps}}}$\",\n",
    "    #     })\n",
    "\n",
    "    # for eps in EPSS:\n",
    "    #     methods.update({\n",
    "    #         f\"frank-wolfe-macro-f1-eps={eps}_proba_threshold={thr}\": f\"\\\\InfFWMacF$_{{\\\\epsilon={eps}}}$\",\n",
    "    #     })\n",
    "\n",
    "    # for eps in EPSS:\n",
    "    #     methods.update({\n",
    "    #         f\"frank-wolfe-macro-jaccard-score-eps={eps}_proba_threshold={thr}\": f\"\\\\InfFWMacJS$_{{\\\\epsilon={eps}}}$\",\n",
    "    #     })\n",
    "\n",
    "\n",
    "    # for eps in EPSS:\n",
    "    #     methods.update({\n",
    "    #         f\"block-coord-macro-gmean-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacGM$_{{\\\\epsilon={eps}}}$\",\n",
    "    #         f\"frank-wolfe-macro-gmean-eps={eps}\": f\"\\\\InfFWMacGM$_{{\\\\epsilon={eps}}}$\",\n",
    "    #     })\n",
    "\n",
    "    # for eps in EPSS:\n",
    "    #     methods.update({\n",
    "    #         f\"block-coord-macro-hmean-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacHM$_{{\\\\epsilon={eps}}}$\",\n",
    "    #         f\"frank-wolfe-macro-hmean-eps={eps}\": f\"\\\\InfFWMacHM$_{{\\\\epsilon={eps}}}$\",\n",
    "    #     })\n",
    "\n",
    "\n",
    "\n",
    "    formats = [\"\\\\textbf{{{}}}\", \"\\\\textit{{{}}}\"]\n",
    "\n",
    "    table = \"\"\n",
    "    for e, (experiment, experiment_label) in enumerate(experiments.items()):\n",
    "        results = []\n",
    "        prev_method = \"\"\n",
    "        for method, method_label in methods.items():\n",
    "            method_results = {\n",
    "                \"_method\": method,\n",
    "                \"method\": method_label\n",
    "            }\n",
    "            if \"midrule\" in method:\n",
    "                results.append(method_results)\n",
    "                continue\n",
    "\n",
    "            for seed in seeds:\n",
    "                filename = f\"{experiment}/{method}_sample_test_labels_k={top_k}_v={val_split}_s=13_sample_s={seed}_results.json\"\n",
    "                if not os.path.exists(filename):\n",
    "                    filename = f\"{experiment}/{method}_k={top_k}_v={val_split}_s={seed}_results.json\"\n",
    "\n",
    "                if not os.path.exists(filename):\n",
    "                    filename = filename.replace(\"org5\", \"org3\")\n",
    "                \n",
    "                if not os.path.exists(filename):\n",
    "                    filename = filename.replace(\"org3\", \"org2\")\n",
    "                    \n",
    "                if os.path.exists(filename):\n",
    "                    with open(filename, \"r\") as f:\n",
    "                        result_file_data = json.load(f)\n",
    "                    for metric, metric_label in metrics.items():\n",
    "                        metric = f\"{metric}@{top_k}\"\n",
    "                        if metric in result_file_data:\n",
    "                            method_results.setdefault(metric, []).append(result_file_data[metric] * multiplier)\n",
    "                else:\n",
    "                    #print(f\"File {filename} not found\")\n",
    "                    pass\n",
    "\n",
    "            for k, v in list(method_results.items()):\n",
    "                if isinstance(v, list) and isinstance(v[0], float):\n",
    "                    method_results[k] = np.mean(v)\n",
    "                    if add_std:\n",
    "                        std = np.std(v)\n",
    "                        if method in basic_methods and std == 0:\n",
    "                           continue \n",
    "                        method_results[f\"{k}_std\"] = np.std(v)\n",
    "\n",
    "            for metric in metrics.keys():\n",
    "                if metric in method and metric in prev_method and method.split(\"-\")[0] == prev_method.split(\"-\")[0]:\n",
    "                    metric_at_k = f\"{metric}@{top_k}\"\n",
    "                    new_val = method_results.get(metric_at_k, 0)\n",
    "                    prev_val = results[-1].get(metric_at_k, 0)\n",
    "                    if new_val > prev_val and isinstance(new_val, float):\n",
    "                        results[-1] = method_results\n",
    "                    break\n",
    "            else:\n",
    "                results.append(method_results)\n",
    "            prev_method = method\n",
    "\n",
    "        for r in results:\n",
    "            for k, v in r.items():\n",
    "                if isinstance(v, float):\n",
    "                    r[k] = np.round(v, 2)\n",
    "\n",
    "        # Specialized method worst results\n",
    "        specialized_method_worst_results = {}\n",
    "        bca_method_results = {}\n",
    "        fw_method_results = {}\n",
    "\n",
    "        for i, r in enumerate(results):\n",
    "            method = r[\"_method\"]\n",
    "            for metric in metrics.keys():\n",
    "                if \"_std\" in metric:\n",
    "                    continue\n",
    "\n",
    "                metric_at_k = f\"{metric}@{top_k}\"\n",
    "                if (metric in method or (\"instance-recall\" in metric and method == \"optimal-instance-precision\")) and metric_at_k in r:\n",
    "                    if isinstance(r[metric_at_k], float):\n",
    "                        specialized_method_worst_results[metric_at_k] = min(specialized_method_worst_results.get(metric_at_k,1000), r[metric_at_k])\n",
    "                    if \"block\" in method:\n",
    "                        bca_method_results[metric_at_k] = min(bca_method_results.get(metric_at_k,1000), r[metric_at_k])\n",
    "                    if \"frank\" in method:\n",
    "                        fw_method_results[metric_at_k] = min(fw_method_results.get(metric_at_k,1000), r[metric_at_k])\n",
    "\n",
    "        # print(specialized_method_worst_results)\n",
    "        # print(bca_method_results)\n",
    "        # print(fw_method_results)\n",
    "\n",
    "        # Select best in column\n",
    "        for metric in list(metrics.keys()):\n",
    "            if \"_std\" in metric:\n",
    "                continue\n",
    "            \n",
    "            metric_at_k = f\"{metric}@{top_k}\"\n",
    "            column = np.array([result.get(metric_at_k, 0) for result in results])\n",
    "            argsort = np.flip(np.argsort(column))\n",
    "            vals = column[argsort]\n",
    "            for result in results:\n",
    "                if metric_at_k not in result:\n",
    "                    continue\n",
    "\n",
    "                if add_std and metric_at_k + \"_std\" in result:\n",
    "                    formated_result = f\"\\\\makecell{{\\\\linespread{{1.0}} {result[metric_at_k]:.2f} \\\\\\\\ {{\\\\scriptsize $\\\\pm$ {result[metric_at_k+'_std']:.2f}}}}}\"\n",
    "                    del result[metric_at_k + \"_std\"]\n",
    "                else:\n",
    "                    formated_result = f\"{result[metric_at_k]:.2f}\"\n",
    "\n",
    "                if result[metric_at_k] < specialized_method_worst_results.get(metric_at_k, 0):\n",
    "                    method = r[\"_method\"]\n",
    "                    result[metric_at_k] = f\"{{\\\\color{{gray!75}} {formated_result}}}\"\n",
    "                else:\n",
    "                    result[metric_at_k] = formated_result\n",
    "                    \n",
    "                    # if \"block\" in method and (result[metric_at_k] < bca_method_results.get(metric_at_k,0) or result[metric_at_k] < specialized_method_worst_results.get(metric_at_k,0)):\n",
    "                    #     result[metric_at_k] = f\"{{\\\\color{{gray!75}} {result[metric_at_k]:.2f}}}\"\n",
    "                    # elif \"frank\" in method and result[metric_at_k] < fw_method_results.get(metric_at_k,0) or result[metric_at_k] < specialized_method_worst_results.get(metric_at_k,0)):\n",
    "                    #     result[metric_at_k] = f\"{{\\\\color{{gray!75}} {result[metric_at_k]:.2f}}}\"\n",
    "                    # elif result[metric_at_k] < specialized_method_worst_results.get(metric_at_k,0):\n",
    "                    #     result[metric_at_k] = f\"{{\\\\color{{gray!75}} {result[metric_at_k]:.2f}}}\"\n",
    "            \n",
    "            f = -1\n",
    "            prev_val = -1\n",
    "            for idx, val in zip(argsort, vals):\n",
    "                if prev_val != val:\n",
    "                    f += 1\n",
    "                    if f == len(formats):\n",
    "                        break\n",
    "                results[idx][metric_at_k] = formats[f].format(results[idx][metric_at_k])\n",
    "                prev_val = val\n",
    "\n",
    "            # for format, idx in zip(formats, argsort):\n",
    "            #     results[idx][metric_at_k] = format.format(column[idx])\n",
    "\n",
    "        color = \"green!25\"\n",
    "        # Color columns with target\n",
    "        for i, r in enumerate(results):\n",
    "            method = r[\"_method\"]\n",
    "            del r[\"_method\"]\n",
    "            if \"epsilon\" in r[\"method\"]:\n",
    "                r[\"method\"] = r[\"method\"].split(\"$\")[0]\n",
    "            for metric in metrics.keys():\n",
    "                metric_at_k = f\"{metric}@{top_k}\"\n",
    "                if (metric in method or (\"instance-recall\" in metric and method == \"optimal-instance-precision\")) and metric_at_k in results[i]:\n",
    "                    mark = \"\"\n",
    "                    if \"instance-recall\" in metric:\n",
    "                        if \"sys\" not in experiment:\n",
    "                            color = \"blue!25\"\n",
    "                        else:\n",
    "                            color = \"blue!12\"\n",
    "                    else:\n",
    "                        color = \"green!25\"\n",
    "                    if \"instance-recall\" in metric:\n",
    "                        mark = \"*\"\n",
    "                    if isinstance(results[i][metric_at_k], str):\n",
    "                        results[i][metric_at_k] = f\"\\\\cellcolor{{{color}}}{mark} {results[i][metric_at_k]}\"\n",
    "                    else:\n",
    "                        results[i][metric_at_k] = f\"\\\\cellcolor{{{color}}}{mark} {results[i][metric_at_k]:.2f}\"\n",
    "        \n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "        \n",
    "        table += \"\\n\"\n",
    "        if e % per_page == 0:\n",
    "            table += \"\\\\begin{table}\\n\"\n",
    "            if e == 0:\n",
    "                table += table_header\n",
    "            if add_std:\n",
    "                table += \"\\\\scriptsize\\n\"\n",
    "            else:\n",
    "                table += \"\\\\small\\n\"\n",
    "            table += \"\"\"\n",
    "\\\\centering\n",
    "\\\\resizebox{\\\\linewidth}{!}{\n",
    "\\\\begin{tabular}{l|rrr|rrrrrr}\n",
    "\\\\toprule\n",
    "    Method & \\\\multicolumn{3}{c|}{Instance $@__K__$} & \\\\multicolumn{6}{c}{Macro $@__K__$} \\\\\\\\\n",
    "    & \\\\multicolumn{1}{c}{P} & \\\\multicolumn{1}{c}{PS} & \\\\multicolumn{1}{c|}{R} \n",
    "    & \\\\multicolumn{1}{c}{P} & \\\\multicolumn{1}{c}{R} & \\\\multicolumn{1}{c}{BA} & \n",
    "    \\\\multicolumn{1}{c}{F$_1$} & \\\\multicolumn{1}{c}{JS} & \\\\multicolumn{1}{c}{Cov} \\\\\\\\\n",
    "\"\"\".replace(\"__K__\", str(top_k))\n",
    "\n",
    "        table += f\"\\\\midrule\\n\"\n",
    "        table += f\"\\\\multicolumn{{10}}{{c}}{{{experiment_label}}} \\\\\\\\\\n\"\n",
    "\n",
    "        # Print the results as a latex table\n",
    "        latex_table = df.to_latex(index=False, float_format=\"{:0.2f}\".format)\n",
    "        #latex_table = df.to_latex(index=False)\n",
    "        table += \"\\n    \".join(latex_table.split(\"\\n\")[3:-3]).replace(\"\\midrule & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN \\\\\\\\\", \"\\midrule\")\n",
    "\n",
    "        if e % per_page == per_page - 1 or e == len(experiments) - 1:\n",
    "            table += \"\"\"\n",
    "\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"tables_thesis\", exist_ok=True)\n",
    "\n",
    "syn_exp_dir = \"results_thesis_syn4\"\n",
    "org_exp_dir = \"results_thesis_org3\"\n",
    "\n",
    "experiments = {\n",
    "    f\"../{org_exp_dir}/rcv1x_100_plt\": \"RCV1x-2K\",\n",
    "    f\"../{org_exp_dir}/eurlex_100_plt\": \"Eurlex-4K\",\n",
    "    f\"../{org_exp_dir}/EURLex-4.3K_100_plt\": \"Eurlex-4.3K\",\n",
    "    f\"../{org_exp_dir}/amazonCat_100_plt\": \"AmazonCat-13K\",\n",
    "    f\"../{org_exp_dir}/amazonCat-14K_100_plt\": \"AmazonCat-14K\",\n",
    "    f\"../{org_exp_dir}/wiki10_100_plt\": \"Wiki10-31K\",\n",
    "    #f\"../{org_exp_dir}/deliciousLarge_100_plt\": \"DeliciousLarge-200K\",\n",
    "    f\"../{org_exp_dir}/wikiLSHTC_100_plt\": \"WikiLSHTC-325K\",\n",
    "    f\"../{org_exp_dir}/WikipediaLarge-500K_100_plt\": \"WikipediaLarge-500K\",\n",
    "    f\"../{org_exp_dir}/amazon_100_plt\": \"Amazon-670K\",\n",
    "}\n",
    "\n",
    "header_main = r\"\"\"\n",
    "\\caption{Results (\\%) on \\emph{original} XMLC datasets with marginal conditional probabilities coming from PLT model for $k = 5$.\n",
    "The \\smash{\\colorbox{green!25}{green background}} indicates cells in which the inference algorithm matches the metric it optimizes. \n",
    "The {\\color{gray!75} gray text} indicate results below all the results with \\smash{\\colorbox{green!25}{green background}} for the given metric. \n",
    "The best results are in \\textbf{bold}, and the second best are in \\textit{italic}.\n",
    "* -- while \\InfTopK{} in general is not optimal for \\RecallAtK{}, we expected it to be the closest to the optimal solution, and we mark \\smash{\\colorbox{blue!12}{blue background}}\n",
    "}\n",
    "\\label{tab:main-plt-results}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"tables_thesis/results-main-plt.tex\", \"w\") as f:\n",
    "    f.write(generate_table_with_results(experiments, table_header=header_main, per_page=3, add_std=False, top_k=5))\n",
    "\n",
    "header_app = r\"\"\"\n",
    "\\caption{Results (\\%) on \\emph{original} XMLC datasets with marginal conditional probabilities coming from PLT model for $k \\in \\{1, 3, 5\\}$.\n",
    "The \\smash{\\colorbox{green!25}{green background}} indicates cells in which the inference algorithm matches the metric it optimizes. \n",
    "The {\\color{gray!75} gray text} indicate results below all the results with \\smash{\\colorbox{green!25}{green background}} for the given metric. \n",
    "The best results are in \\textbf{bold}, and the second best are in \\textit{italic}.\n",
    "* -- while \\InfTopK{} in general is not optimal for \\RecallAtK{}, we expected it to be the closest to the optimal solution, and we mark \\smash{\\colorbox{blue!12}{blue background}}.\n",
    "}\n",
    "\\label{tab:app-plt-results}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"tables_thesis/results-app-plt.tex\", \"w\") as f:\n",
    "    table = generate_table_with_results(experiments, table_header=header_app, per_page=2, add_std=True, top_k=1)\n",
    "    table += generate_table_with_results(experiments, per_page=2, add_std=True, top_k=3)\n",
    "    table += generate_table_with_results(experiments, per_page=2, add_std=True, top_k=5)\n",
    "    f.write(table)\n",
    "\n",
    "\n",
    "experiments = {\n",
    "    f\"../{syn_exp_dir}/rcv1x_100_plt\": \"Synthetic RCV1x-2K\",\n",
    "    f\"../{syn_exp_dir}/eurlex_100_plt\": \"Synthetic Eurlex-4K\",\n",
    "    f\"../{syn_exp_dir}/EURLex-4.3K_100_plt\": \"Synthetic Eurlex-4.3K\",\n",
    "    f\"../{syn_exp_dir}/amazonCat_100_plt\": \"Synthetic AmazonCat-13K\",\n",
    "    f\"../{syn_exp_dir}/amazonCat-14K_100_plt\": \"Synthetic AmazonCat-14K\",\n",
    "    f\"../{syn_exp_dir}/wiki10_100_plt\": \"Synthetic Wiki10-31K\",\n",
    "    f\"../{syn_exp_dir}/wikiLSHTC_100_plt\": \"Synthetic WikiLSHTC-325K\",\n",
    "    f\"../{syn_exp_dir}/WikipediaLarge-500K_100_plt\": \"Synthetic WikipediaLarge-500K\",\n",
    "    f\"../{syn_exp_dir}/amazon_100_plt\": \"Synthetic Amazon-670K\",\n",
    "}\n",
    "\n",
    "header_main = r\"\"\"\n",
    "\\caption{Results (\\%)  on \\emph{synthetic versions} of XMLC datasets with ideal estimates of marginal conditional probabilities $\\Marginals(\\Instance) = \\PredMarginals(\\Instance)$ for $k = 5$. \n",
    "The \\smash{\\colorbox{green!25}{green background}} indicates cells in which the inference algorithm matches the metric it optimizes. \n",
    "The {\\color{gray!75} gray text} indicate results below all the results with \\smash{\\colorbox{green!25}{green background}} for the given metric. \n",
    "The best results are in \\textbf{bold}, and the second best are in \\textit{italic}.\n",
    "* -- because in this experiment we sample labels independently, \\InfTopK{} becomes optimal strategy for \\RecallAtK{} as showed in \\cref{thm:prec-recall-equ-with-independence}.\n",
    "}\n",
    "\\label{tab:main-plt-syn-results}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"tables_thesis/results-main-plt-syn.tex\", \"w\") as f:\n",
    "    f.write(generate_table_with_results(experiments, table_header=header_main, per_page=3, add_std=False, top_k=5))\n",
    "\n",
    "header_app = r\"\"\"\n",
    "\\caption{Results (\\%) on \\emph{synthetic versions} of XMLC datasets with ideal estimates of marginal conditional probabilities $\\Marginals(\\Instance) = \\PredMarginals(\\Instance)$ for $k \\in \\{1, 3, 5\\}$.\n",
    "The \\smash{\\colorbox{green!25}{green background}} indicates cells in which the inference algorithm matches the metric it optimizes. \n",
    "The {\\color{gray!75} gray text} indicate results below all the results with \\smash{\\colorbox{green!25}{green background}} for the given metric. \n",
    "The best results are in \\textbf{bold}, and the second best are in \\textit{italic}.\n",
    "* -- because in this experiment we sample labels independently, \\InfTopK{} becomes optimal strategy for \\RecallAtK{} as showed in \\cref{thm:prec-recall-equ-with-independence}.\n",
    "}\n",
    "\\label{tab:app-plt-syn-results}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"tables_thesis/results-app-plt-syn.tex\", \"w\") as f:\n",
    "    table = generate_table_with_results(experiments, table_header=header_app, per_page=2, add_std=True, top_k=1)\n",
    "    table += generate_table_with_results(experiments, per_page=2, add_std=True, top_k=3)\n",
    "    table += generate_table_with_results(experiments, per_page=2, add_std=True, top_k=5)\n",
    "    f.write(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating the plots\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "from collections.abc import Iterable\n",
    "import os\n",
    "\n",
    "top_k = 5\n",
    "multiplier = 100\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (4, 2), # for smaller plots\n",
    "    #\"figure.figsize\": (4, 2.5), # ICLR paper\n",
    "    #\"figure.figsize\": (4, 3), # NeurIPS paper\n",
    "    \"figure.dpi\": 300,\n",
    "    \"figure.autolayout\": False,\n",
    "    \"text.usetex\": True,\n",
    "    'mathtext.fontset': 'stix',\n",
    "    'font.family': 'STIXGeneral',\n",
    "    'savefig.transparent': False,\n",
    "})\n",
    "\n",
    "plt.rcParams[\"text.latex.preamble\"] = r\"\"\"\n",
    "\\usepackage[T1]{fontenc}\n",
    "\\usepackage{bold-extra}\n",
    "\\usepackage{amsmath}\n",
    "\\usepackage{amsfonts}\n",
    "\\usepackage{amssymb}\n",
    "\\newcommand{\\InfTopK}{Top-K}\n",
    "\\newcommand{\\InfPSK}{PS-K}\n",
    "\\newcommand{\\InfPowerK}{Pow-K}\n",
    "\\newcommand{\\InfLogK}{Log-K}\n",
    "\\newcommand{\\InfMacR}{Macro-R$_{\\text{prior}}$}\n",
    "\\newcommand{\\InfMacBA}{Macro-BA$_{\\text{prior}}$}\n",
    "\\newcommand{\\InfBCA}[1]{BCA(#1)}\n",
    "\\newcommand{\\InfBCAMacP}{\\InfBCA{Macro-P}}\n",
    "\\newcommand{\\InfBCAMacR}{\\InfBCA{Macro-R}}\n",
    "\\newcommand{\\InfBCAMacF}{\\InfBCA{Macro-F1}}\n",
    "\\newcommand{\\InfBCAMacBA}{\\InfBCA{Macro-BA}}\n",
    "\\newcommand{\\InfBCAMacJ}{\\InfBCA{Macro-J}}\n",
    "\\newcommand{\\InfBCAMacGM}{\\InfBCA{Macro-G-M}}\n",
    "\\newcommand{\\InfBCAMacHM}{\\InfBCA{Macro-H-M}}\n",
    "\\newcommand{\\InfBCACov}{\\InfBCA{Cov}}\n",
    "\\newcommand{\\InfFW}[1]{FW(#1)}\n",
    "\\newcommand{\\InfFWMacP}{\\InfFW{Macro-P}}\n",
    "\\newcommand{\\InfFWMacR}{\\InfFW{Macro-R}}\n",
    "\\newcommand{\\InfFWMacF}{\\InfFW{Macro-F1}}\n",
    "\\newcommand{\\InfFWMacBA}{\\InfFW{Macro-BA}}\n",
    "\\newcommand{\\InfFWMacJ}{\\InfFW{Macro-J}}\n",
    "\\newcommand{\\InfFWMacGM}{\\InfFW{Macro-G-M}}\n",
    "\\newcommand{\\InfFWMacHM}{\\InfFW{Macro-H-M}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath) as file:\n",
    "        return json.load(file)\n",
    "\n",
    "\n",
    "def plot_results(experiment, results, methods, x_axis, y_axis,\n",
    "                 x_axis_label=None, y_axis_label=None, title=None, legend=False, add_std=False, on_plot_labels=False):\n",
    "    all_labels = []\n",
    "    x_rep = []\n",
    "    y_rep = []\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_alpha(0)\n",
    "\n",
    "    plt.clf()\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    for n, v in methods.items():\n",
    "        x_vals = []\n",
    "        y_vals = []\n",
    "        x_errors = []\n",
    "        y_errors = []\n",
    "        labels = []\n",
    "        if isinstance(v, str):\n",
    "            try:\n",
    "                labels.append(v)\n",
    "                x_vals.append(results[n][x_axis])\n",
    "                y_vals.append(results[n][y_axis])\n",
    "                x_errors.append(results[n][f\"{x_axis}_std\"])\n",
    "                y_errors.append(results[n][f\"{y_axis}_std\"])\n",
    "            except KeyError as e:\n",
    "                print(f\"KeyError: {n} {x_axis} {y_axis}\")\n",
    "                print(f\"Available keys: {results[n].keys()}\")\n",
    "                raise e\n",
    "        elif isinstance(v, dict):\n",
    "            for n2, v2 in v.items():\n",
    "                try:\n",
    "                    labels.append(v2)\n",
    "                    x_vals.append(results[n2][x_axis])\n",
    "                    y_vals.append(results[n2][y_axis])\n",
    "                    x_errors.append(results[n2][f\"{x_axis}_std\"])\n",
    "                    y_errors.append(results[n2][f\"{y_axis}_std\"])\n",
    "                except KeyError as e:\n",
    "                    print(f\"KeyError: {n2} {x_axis} {y_axis}\")\n",
    "                    print(f\"Available keys: {results[n2].keys()}\")\n",
    "                    raise e\n",
    "\n",
    "        if on_plot_labels:\n",
    "            all_labels.extend([plt.text(x, y, l, size=8) for x, y, l in zip(x_vals, y_vals, labels) if len(l)])\n",
    "        x_rep.extend(x_vals)\n",
    "        y_rep.extend(y_vals)\n",
    "        plot_kwargs = {}\n",
    "        if isinstance(v, str):\n",
    "            plot_kwargs[\"label\"] = v\n",
    "        else:\n",
    "            plot_kwargs[\"linestyle\"] = \"-\"\n",
    "            plot_kwargs[\"label\"] = labels[0] #+ \" - \" + labels[-1]\n",
    "        \n",
    "        x_vals = np.array(x_vals)\n",
    "        y_vals = np.array(y_vals)\n",
    "        x_errors = np.array(x_errors)\n",
    "        y_errors = np.array(y_errors)\n",
    "\n",
    "        plt.plot(x_vals, y_vals, '.', **plot_kwargs)\n",
    "        if add_std:\n",
    "            plt.fill_between(x=x_vals, y1 = y_vals - y_errors, y2= y_vals + y_errors, alpha=0.3)\n",
    "        #plt.errorbar(x_vals, y_vals, xerr=x_errors, yerr=y_errors, fmt='.', linestyle=\"-\", linewidth=1, capsize=2, capthick=1)\n",
    "\n",
    "    if on_plot_labels:\n",
    "        adjust_text(all_labels, x_rep, y_rep, \n",
    "                    min_arrow_len=50,\n",
    "                    #force_text=(0.2, 0.5),\n",
    "                    #force_static=(0.2, 0.5),\n",
    "                    #force_explode=(0.2, 0.5),\n",
    "                    #expand=(1.4, 1.6),\n",
    "                    time_lim=1, \n",
    "                    explode_radius=100,\n",
    "                    arrowprops={\"arrowstyle\": \"->\", \"lw\": 0.5},\n",
    "                    expand=(1.4, 1.5),\n",
    "                    only_move='y-', #Only allow movement to the left\n",
    "                    #only_move = {\"text\": \"y\", \"static\": \"y\", \"explode\": \"y\", \"pull\": \"y\"},\n",
    "                    )\n",
    "    \n",
    "    if \"syn\" in experiment:\n",
    "        experiment = experiment.split(\"/\")[-1] + '_sys'\n",
    "        #title = \"Synthetic \" + title\n",
    "    else:\n",
    "        experiment = experiment.split(\"/\")[-1] + '_org'\n",
    "\n",
    "    if legend:\n",
    "        plt.legend(loc=3, prop={'size': 6})\n",
    "        #plt.legend()\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    \n",
    "    if x_axis_label is not None:\n",
    "        plt.xlabel(x_axis_label)\n",
    "    \n",
    "    if y_axis_label is not None:\n",
    "        plt.ylabel(y_axis_label)\n",
    "\n",
    "    # plt.ylim([0, 1])\n",
    "    # plt.xlim([0, 1])\n",
    "    plt.margins(0.15, 0.25)\n",
    "    plt.plot()\n",
    "    \n",
    "\n",
    "    os.makedirs(\"plots_thesis\", exist_ok=True)\n",
    "    output = f\"plots_thesis/{experiment}_mixed_{x_axis.replace('@', '_')}_{y_axis.replace('@', '_')}\"\n",
    "    plt.savefig(output + \".pdf\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    f\"../{org_exp_dir}/rcv1x_100_plt\": \"RCV1x-2K\",\n",
    "    f\"../{org_exp_dir}/eurlex_100_plt\": \"Eurlex-4K\",\n",
    "    f\"../{org_exp_dir}/EURLex-4.3K_100_plt\": \"Eurlex-4.3K\",\n",
    "    f\"../{org_exp_dir}/amazonCat_100_plt\": \"AmazonCat-13K\",\n",
    "    f\"../{org_exp_dir}/amazonCat-14K_100_plt\": \"AmazonCat-14K\",\n",
    "    f\"../{org_exp_dir}/wiki10_100_plt\": \"Wiki10-31K\",\n",
    "    #f\"../{org_exp_dir}/deliciousLarge_100_plt\": \"DeliciousLarge-200K\",\n",
    "    f\"../{org_exp_dir}/wikiLSHTC_100_plt\": \"WikiLSHTC-325K\",\n",
    "    f\"../{org_exp_dir}/WikipediaLarge-500K_100_plt\": \"WikipediaLarge-500K\",\n",
    "    f\"../{org_exp_dir}/amazon_100_plt\": \"Amazon-670K\",\n",
    "\n",
    "\n",
    "    f\"../{syn_exp_dir}/rcv1x_100_plt\": \"Synthetic RCV1x-2K\",\n",
    "    f\"../{syn_exp_dir}/eurlex_100_plt\": \"Synthetic Eurlex-4K\",\n",
    "    f\"../{syn_exp_dir}/EURLex-4.3K_100_plt\": \"Synthetic Eurlex-4.3K\",\n",
    "    f\"../{syn_exp_dir}/amazonCat_100_plt\": \"Synthetic AmazonCat-13K\",\n",
    "    f\"../{syn_exp_dir}/amazonCat-14K_100_plt\": \"Synthetic AmazonCat-14K\",\n",
    "    f\"../{syn_exp_dir}/wiki10_100_plt\": \"Synthetic Wiki10-31K\",\n",
    "    f\"../{syn_exp_dir}/wikiLSHTC_100_plt\": \"Synthetic WikiLSHTC-325K\",\n",
    "    f\"../{syn_exp_dir}/WikipediaLarge-500K_100_plt\": \"Synthetic WikipediaLarge-500K\",\n",
    "    f\"../{syn_exp_dir}/amazon_100_plt\": \"Synthetic Amazon-670K\",\n",
    "}\n",
    "\n",
    "\n",
    "METRICS = [\"macro-f1\", \"macro-precision\", \"macro-recall\"]\n",
    "METRIC_LABELS = [\"Macro-F1\", \"Macro-Precision\", \"Macro-Recall\"]\n",
    "METRICS = [\"macro-f1\", \"macro-recall\"]\n",
    "METRIC_LABELS = [\"Macro-F1\", \"Macro-Recall\"]\n",
    "METRIC_LABELS_SHORT = [\"Macro-F1\", \"Macro-R\"]\n",
    "\n",
    "for METRIC, METRIC_LABEL, METRIC_LABEL_SHORT in zip(METRICS, METRIC_LABELS, METRIC_LABELS_SHORT):\n",
    "\n",
    "    methods = {\n",
    "        \"optimal-instance-precision\": \"\\\\InfTopK\",\n",
    "        \"optimal-instance-ps-precision\": \"\\\\InfPSK\",\n",
    "        \"power-law-with-beta=0.25\": \"\\\\InfPowerK\",\n",
    "        \"power-law-with-beta=0.5\": \"\\\\InfPowerK\",\n",
    "        \"power-law-with-beta=0.75\": \"\\\\InfPowerK\",\n",
    "        \"log\": \"\\\\InfLogK\",\n",
    "        \"optimal-macro-recall\": \"\\\\InfMacR\",\n",
    "        \"optimal-macro-balanced-accuracy\": \"\\\\InfMacBA\",\n",
    "    }\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"block-coord-macro-precision-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacP$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"block-coord-macro-recall-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacR$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"block-coord-macro-balanced-accuracy-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacBA$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"block-coord-macro-f1-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacF$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"block-coord-macro-jaccard-score-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacJ$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    methods.update({\n",
    "        f\"block-coord-coverage-tol={TOL}\": \"\\\\InfBCACov\",\n",
    "    })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"frank-wolfe-macro-precision-eps={eps}\": f\"\\\\InfFWMacP$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"frank-wolfe-macro-recall-eps={eps}\": f\"\\\\InfFWMacR$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"frank-wolfe-macro-balanced-accuracy-eps={eps}\": f\"\\\\InfFWMacBA$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"frank-wolfe-macro-f1-eps={eps}\": f\"\\\\InfFWMacF$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"frank-wolfe-macro-jaccard-score-eps={eps}\": f\"\\\\InfFWMacJ$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    ALPHAS = [0.9, 0.7, 0.5, 0.3, 0.1, 0.05]\n",
    "    for a in ALPHAS:\n",
    "        #for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"power-law-with-beta={a}\": f\"\\\\InfPowerK\",\n",
    "        })\n",
    "        for eps in [1e-8, 1e-6, 1e-4]:\n",
    "            methods.update({\n",
    "                #f\"block-coord-mixed-precision-macro-precision-alpha={a}-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacBA$_{{\\\\alpha={a}}}$\",\n",
    "                f\"block-coord-mixed-precision-{METRIC}-alpha={a}-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacF$_{{\\\\alpha={a}}}$\",\n",
    "                #f\"block-coord-mixed-precision-macro-recall-alpha={a}-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacR$_{{\\\\alpha={a}}}$\",\n",
    "            })\n",
    "        for eps in EPSS:\n",
    "            methods.update({\n",
    "                f\"frank-wolfe-mixed-precision-{METRIC}-alpha={a}-eps={eps}\": f\"\\\\InfFWMacF$_{{\\\\alpha={a}}}$\",\n",
    "            })\n",
    "\n",
    "\n",
    "    plots = {\n",
    "        \"block-coord-mixed-precision-{METRIC}\": {\n",
    "            f\"block-coord-{METRIC}\": r\"\\InfBCA{$(1 \\! - \\! \\lambda) \\text{P}@k \\! + \\! \\lambda \\text{\" + METRIC_LABEL_SHORT + r\"}@k$}\",\n",
    "            #f\"block-coord-mixed-precision-{METRIC}-alpha=0.95\": f\"\",\n",
    "            f\"block-coord-mixed-precision-{METRIC}-alpha=0.9\": f\"\",\n",
    "            f\"block-coord-mixed-precision-{METRIC}-alpha=0.7\": f\"\",\n",
    "            f\"block-coord-mixed-precision-{METRIC}-alpha=0.5\": f\"\",\n",
    "            f\"block-coord-mixed-precision-{METRIC}-alpha=0.3\": f\"\",\n",
    "            f\"block-coord-mixed-precision-{METRIC}-alpha=0.1\": f\"\",\n",
    "            f\"block-coord-mixed-precision-{METRIC}-alpha=0.05\": f\"\",\n",
    "            \"optimal-instance-precision\": \"\",\n",
    "        },\n",
    "        # \"power-law\": {\n",
    "        #     f\"optimal-macro-recall\": f\"\",\n",
    "        #     f\"power-law-with-beta=0.9\": f\"\",\n",
    "        #     f\"power-law-with-beta=0.7\": f\"\",\n",
    "        #     f\"power-law-with-beta=0.5\": f\"\",\n",
    "        #     f\"power-law-with-beta=0.3\": f\"\",\n",
    "        #     f\"power-law-with-beta=0.1\": f\"\",\n",
    "        #     \"optimal-instance-precision\": \"\",\n",
    "        # },\n",
    "        \"frank-wolfe-mixed-precision-{METRIC}\": {\n",
    "            f\"frank-wolfe-{METRIC}\": r\"\\InfFW{$(1 \\! - \\! \\lambda) \\text{P}@k \\! + \\! \\lambda \\text{\" + METRIC_LABEL_SHORT + r\"}@k$}\",\n",
    "            #f\"frank-wolfe-mixed-precision-{METRIC}-alpha=0.95\": f\"\",\n",
    "            f\"frank-wolfe-mixed-precision-{METRIC}-alpha=0.9\": f\"\",\n",
    "            f\"frank-wolfe-mixed-precision-{METRIC}-alpha=0.7\": f\"\",\n",
    "            f\"frank-wolfe-mixed-precision-{METRIC}-alpha=0.5\": f\"\",\n",
    "            f\"frank-wolfe-mixed-precision-{METRIC}-alpha=0.3\": f\"\",\n",
    "            f\"frank-wolfe-mixed-precision-{METRIC}-alpha=0.1\": f\"\",\n",
    "            f\"frank-wolfe-mixed-precision-{METRIC}-alpha=0.05\": f\"\",\n",
    "            \"optimal-instance-precision\": \"\",\n",
    "        },\n",
    "        \"optimal-instance-precision\": \"\\\\InfTopK\",\n",
    "        \"optimal-instance-ps-precision\": \"\\\\InfPSK\",\n",
    "        \"power-law-with-beta=0.25\": \"\\\\InfPowerK$_{\\\\beta=0.25}$\",\n",
    "        \"power-law-with-beta=0.5\": \"\\\\InfPowerK$_{\\\\beta=0.5}$\",\n",
    "        #\"power-law-with-beta=0.75\": \"\\\\InfPowerK$_{\\\\beta=0.75}$\",\n",
    "        \"log\": \"\\\\InfLogK\",\n",
    "        #\"optimal-macro-recall\": \"\\\\InfMacR\",\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    for e, (experiment, experiment_label) in enumerate(experiments.items()):\n",
    "        print(f\"Processing {e}: {experiment} - {experiment_label}\")\n",
    "        results = []\n",
    "        prev_method = \"\"\n",
    "        for method, method_label in methods.items():\n",
    "            _method = method.split(\"-eps\")[0].split(\"-tol\")[0]\n",
    "            method_results = {\n",
    "                \"_method\": _method,\n",
    "                \"method\": method_label\n",
    "            }\n",
    "            if \"midrule\" in method:\n",
    "                results.append(method_results)\n",
    "                continue\n",
    "\n",
    "            for seed in seeds:\n",
    "                filename = f\"{experiment}/{method}_k={top_k}_v={val_split}_s={seed}_results.json\"\n",
    "                if not os.path.exists(filename):\n",
    "                    filename = filename.replace(\"org5\", \"org3\")\n",
    "                \n",
    "                if not os.path.exists(filename):\n",
    "                    filename = filename.replace(\"org3\", \"org2\")\n",
    "                    filename = filename.replace(\"syn3\", \"syn2\")\n",
    "\n",
    "                if os.path.exists(filename):\n",
    "                    with open(filename, \"r\") as f:\n",
    "                        result_file_data = json.load(f)\n",
    "                    for metric, metric_label in metrics.items():\n",
    "                        metric = f\"{metric}@{top_k}\"\n",
    "                        if metric in result_file_data:\n",
    "                            method_results.setdefault(metric, []).append(result_file_data[metric] * multiplier)\n",
    "                else:\n",
    "                    #print(f\"File {filename} not found\")\n",
    "                    pass\n",
    "            \n",
    "            _method_results = {}\n",
    "            for k, v in method_results.items():\n",
    "                if isinstance(v, list) and isinstance(v[0], float):\n",
    "                    method_results[k] = np.mean(v)\n",
    "                    _method_results[k + \"_std\"] = np.std(v)\n",
    "            method_results.update(_method_results)\n",
    "\n",
    "            for metric in metrics.keys():\n",
    "                if metric in method and metric in prev_method and _method == prev_method:\n",
    "                    metric_at_k = f\"{metric}@{top_k}\"\n",
    "                    new_val = method_results.get(metric_at_k, 0)\n",
    "                    prev_val = results[-1].get(metric_at_k, 0)\n",
    "                    if new_val > prev_val and isinstance(new_val, float):\n",
    "                        results[-1] = method_results\n",
    "                    break\n",
    "            else:\n",
    "                results.append(method_results)\n",
    "            prev_method = _method\n",
    "\n",
    "        for r in results:\n",
    "            for k, v in r.items():\n",
    "                if isinstance(v, float):\n",
    "                    r[k] = np.round(v, 2)\n",
    "\n",
    "        from pprint import pprint\n",
    "        results = {r[\"_method\"]: r for r in results}\n",
    "        plot_results(experiment, results, plots, \n",
    "                    f\"{METRIC}@{top_k}\", \n",
    "                    f\"instance-precision@{top_k}\", \n",
    "                    x_axis_label=f\"{METRIC_LABEL}$@{top_k}$\", \n",
    "                    y_axis_label=f\"Precision$@{top_k}$\", \n",
    "                    title=experiment_label, \n",
    "                    legend=(METRIC == \"macro-recall\" and (e==0 or e == 5 or e == 9 or e == 14)), \n",
    "                    add_std=True,\n",
    "                    on_plot_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
