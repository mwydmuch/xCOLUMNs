{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize results for Marek's thesis\n",
    "\n",
    "This notebook is used to generate latex tables for Marek's thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_vs_top_h_table(\n",
    "    experiments,\n",
    "    base_method = \"optimal-instance-precision-keep-scores\",\n",
    "    table_header = \"\",\n",
    "    multiplier = 100,\n",
    "    per_page = 9,\n",
    "    top_k = 5,\n",
    "):\n",
    "    basic_methods = {\n",
    "        \"optimal-instance-precision\": \"\\\\InfTopK\",\n",
    "        \"optimal-instance-ps-precision\": \"\\\\InfPSK\",\n",
    "    }\n",
    "\n",
    "    metrics = {\n",
    "        \"instance-precision\": \"Precision\",\n",
    "        \"ps-precision\": \"Propensity-scored Prec.\",\n",
    "        \"instance-recall\": \"Recall\",\n",
    "        \"ndcg\": \"nDCG\",\n",
    "        \"midrule\": \"\\\\midrule\",\n",
    "        \"macro-precision\": \"Macro-Precision\",\n",
    "        \"macro-recall\": \"Macro-Recall\",\n",
    "        #\"macro-balanced-accuracy\": \"BA\",\n",
    "        \"macro-f1\": \"Macro-F$_1$\",\n",
    "        #\"macro-jaccard-score\": \"JS\",\n",
    "        # \"macro-gmean\": \"GM\",\n",
    "        # \"macro-hmean\": \"HM\",\n",
    "        \"coverage\": \"Coverage\"\n",
    "    }\n",
    "\n",
    "    table = \"\"\n",
    "    for e, (experiment, experiment_label) in enumerate(experiments.items()):\n",
    "        all_results = {}\n",
    "        for top_k in [1, 3, 5]:\n",
    "            filename = f\"{experiment}/{base_method}_k={top_k}_v=0.0_s=13_results.json\"\n",
    "            if os.path.exists(filename):\n",
    "                with open(filename, \"r\") as f:\n",
    "                    result_file_data = json.load(f)\n",
    "                for metric, metric_label in metrics.items():\n",
    "                    metric = f\"{metric}@{top_k}\"\n",
    "                    if metric in result_file_data:\n",
    "                        all_results[f\"{metric}_all\"] = result_file_data[metric] * multiplier\n",
    "\n",
    "            filename = filename.replace(\"_k=\", \"_top_labels=0.2_k=\")\n",
    "            filename = filename.replace(\"org2\", \"org4\")\n",
    "            if os.path.exists(filename):\n",
    "                with open(filename, \"r\") as f:\n",
    "                    result_file_data = json.load(f)\n",
    "                for metric, metric_label in metrics.items():\n",
    "                    metric = f\"{metric}@{top_k}\"\n",
    "                    if metric in result_file_data:\n",
    "                        all_results[f\"{metric}_top\"] = result_file_data[metric] * multiplier\n",
    "        \n",
    "        print(all_results)\n",
    "        results = []\n",
    "        for metric, metric_label in metrics.items():\n",
    "            _result = {\"Metric\": metric_label}\n",
    "            for top_k in [1, 3, 5]:\n",
    "                _metric = f\"{metric}@{top_k}\"\n",
    "                _result[f\"{top_k}_all\"] = all_results.get(f\"{_metric}_all\", \"-\")\n",
    "            for top_k in [1, 3, 5]:\n",
    "                _metric = f\"{metric}@{top_k}\"\n",
    "                _ref_value = all_results.get(f\"{_metric}_all\", \"-\")\n",
    "                _value = all_results.get(f\"{_metric}_top\", \"-\")\n",
    "                _diff = None\n",
    "                if _ref_value != \"-\" and _value != \"-\":\n",
    "                    _diff = (_value - _ref_value) / _ref_value * 100\n",
    "                if _value != \"-\":\n",
    "                    _value = f\"{_value:.2f}\"\n",
    "                if _diff is not None:\n",
    "                    color = r\"\\color{green}\"\n",
    "                    if _diff < -5:\n",
    "                        color = r\"\\color{orange}\"\n",
    "                    if _diff < -30:\n",
    "                        color = r\"\\color{red}\"\n",
    "                    _diff = f\" {{\\\\scriptsize {color} ({_diff:.2f}\\\\%)}}\"\n",
    "                _result[f\"{top_k}_top\"] = _value\n",
    "                _result[f\"{top_k}_top_diff\"] = _diff\n",
    "                \n",
    "                \n",
    "            results.append(_result)\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "        \n",
    "        table += \"\\n\"\n",
    "        if e % per_page == 0:\n",
    "            if e == 0:\n",
    "                table += \"\\\\begin{table}\\n\"\n",
    "                table += table_header\n",
    "                table += \"\\\\small\\n\"\n",
    "            table += \"\"\"\n",
    "\\\\centering\n",
    "\\\\resizebox{\\\\linewidth}{!}{\n",
    "\\\\begin{tabular}{l|rrr|rlrlrl}\n",
    "\\\\toprule\n",
    "    Metric & \\\\multicolumn{3}{c|}{With all labels} & \\\\multicolumn{6}{c}{With top 20\\\\% labels} \\\\\\\\\n",
    "    & \\\\multicolumn{1}{c}{$@1$} & \\\\multicolumn{1}{c}{$@3$} & \\\\multicolumn{1}{c|}{$@5$} \n",
    "    & \\\\multicolumn{2}{c}{$@1$} & \\\\multicolumn{2}{c}{$@3$} & \\\\multicolumn{2}{c}{$@5$} \\\\\\\\\n",
    "\"\"\"\n",
    "            table += \"\"\"\n",
    "\\\\centering\n",
    "\\\\resizebox{\\\\linewidth}{!}{\n",
    "\\\\begin{tabular}{l|rrr|rlrlrl}\n",
    "\\\\toprule\n",
    "    Metric & \\\\multicolumn{3}{c|}{With all labels} & \\\\multicolumn{6}{c}{With top 20\\\\% labels} \\\\\\\\\n",
    "    & \\\\multicolumn{1}{c}{$@1$} & \\\\multicolumn{1}{c}{$@3$} & \\\\multicolumn{1}{c|}{$@5$} \n",
    "    & $@1$ & {\\\\scriptsize (diff.)} & $@3$ & {\\\\scriptsize (diff.)} & $@5$ & {\\\\scriptsize (diff.)} \\\\\\\\\n",
    "\"\"\"\n",
    "# Metric & \\\\multicolumn{3}{c|}{Class. with all labels} & \\\\multicolumn{6}{c}{Classifier with top 20\\\\% labels} \\\\\\\\\n",
    "        table += f\"\\\\midrule\\n\"\n",
    "        table += f\"\\\\multicolumn{{10}}{{c}}{{{experiment_label}}} \\\\\\\\\\n\"\n",
    "\n",
    "        # Print the results as a latex table\n",
    "        latex_table = df.to_latex(index=False, float_format=\"{:0.2f}\".format)\n",
    "        #latex_table = df.to_latex(index=False)\n",
    "        table += \"\\n    \".join(latex_table.split(\"\\n\")[3:-3]).replace(\"\\midrule & - & - & - & - & NaN & - & NaN & - & NaN \\\\\\\\\", \"\\midrule\")\n",
    "\n",
    "        if e % per_page == per_page - 1 or e == len(experiments) - 1:\n",
    "            table += \"\"\"\n",
    "\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_exp_dir = \"results_thesis_all_vs_top\"\n",
    "\n",
    "experiments = {\n",
    "    f\"../{org_exp_dir}/rcv1x_100_plt\": \"RCV1x-2K\",\n",
    "    #f\"../{org_exp_dir}/eurlex_100_plt\": \"Eurlex-4K\",\n",
    "    f\"../{org_exp_dir}/EURLex-4.3K_100_plt\": \"Eurlex-4.3K\",\n",
    "    #f\"../{org_exp_dir}/amazonCat_100_plt\": \"AmazonCat-13K\",\n",
    "    f\"../{org_exp_dir}/amazonCat-14K_100_plt\": \"AmazonCat-14K\",\n",
    "    #f\"../{org_exp_dir}/wiki10_100_plt\": \"Wiki10-31K\",\n",
    "    #f\"../{org_exp_dir}/deliciousLarge_100_plt\": \"DeliciousLarge-200K\",\n",
    "    f\"../{org_exp_dir}/wikiLSHTC_100_plt\": \"WikiLSHTC-325K\",\n",
    "    f\"../{org_exp_dir}/WikipediaLarge-500K_100_plt\": \"WikipediaLarge-500K\",\n",
    "    f\"../{org_exp_dir}/amazon_100_plt\": \"Amazon-670K\",\n",
    "}\n",
    "\n",
    "header_main = r\"\"\"\n",
    "\\caption{Results (\\%) of a classifier trained on the full set of labels\n",
    "and a classifier trained with only the top 20\\% of labels (most frequent labels) \n",
    "on different metrics budgeted at $k$ ($@k$).\n",
    "}\n",
    "\\label{tab:all-vs-top-h}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"tables_thesis/results-all-vs-top-h.tex\", \"w\") as f:\n",
    "    f.write(generate_full_vs_top_h_table(experiments, table_header=header_main, per_page=9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSS = [1e-8, 5e-8, 1e-7, 5e-7, 9e-7, 5e-6, 2e-6, 1e-6, 5e-5, 1e-5, 1e-4, 1e-8, 1e-7, 1e-6, 1e-5, 2e-5, 3e-5, 4e-5, 5e-5, 6e-5, 7e-5, 8e-5, 9e-5, 1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 6e-4, 0.00015, 1e-8, 1e-7, 1e-6, 5e-6, 9e-6, 1e-5, 4e-5, 5e-5, 6e-5, 7e-5, 8e-5, 9e-5, 1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 6e-4, 1e-3, 2e-3, 5e-3, 1e-2, 2e-2, 5e-2, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3, 3e-3, 5e-3, 7e-3, 1e-2, 3e-3, 5e-3, 6e-3, 7e-3, 8e-3, 9e-3, 1e-2, 2e-2, 1e-8, 1e-7, 1e-6, 5e-6, 1e-5, 5e-5, 1e-4, 5e-4, 2e-4, 3e-4, 4e-4, 1e-3, 2e-3, 3e-3, 5e-3, 1e-8, 1e-7, 1e-6, 5e-6, 1e-5, 3e-5, 5e-5, 7e-5, 9e-5, 1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 6e-4, 7e-4, 8e-4, 9e-4, 1e-3, 2e-3, 0.004, 0.0004]\n",
    "EPSS = sorted(list(set(EPSS)))\n",
    "TOL = 1e-7\n",
    "seeds = [13, 1988, 1993, 2023, 2024]\n",
    "seeds = [13, 1988, 1993, 2023, 2024]\n",
    "val_split = 0.0\n",
    "\n",
    "metrics = {\n",
    "    \"instance-precision\": \"P\",\n",
    "    \"ps-precision\": \"PS\",\n",
    "    \"instance-recall\": \"R\",\n",
    "    \"macro-precision\": \"P\",\n",
    "    \"macro-recall\": \"R\",\n",
    "    \"macro-balanced-accuracy\": \"BA\",\n",
    "    \"macro-f1\": \"F\",\n",
    "    \"macro-jaccard-score\": \"JS\",\n",
    "    # \"macro-gmean\": \"GM\",\n",
    "    # \"macro-hmean\": \"HM\",\n",
    "    \"coverage\": \"C\"\n",
    "}\n",
    "\n",
    "\n",
    "def generate_table_with_results(\n",
    "    experiments,\n",
    "    table_header = \"\",\n",
    "    multiplier = 100,\n",
    "    per_page = 3,\n",
    "    per_first_page = 0,\n",
    "    continue_prev_tabular = False,\n",
    "    continue_tabular = False,\n",
    "    add_std = False,\n",
    "    top_k = 5,\n",
    "    sampled = False,\n",
    "    add_count = True,\n",
    "    force_h = False,\n",
    "):\n",
    "    basic_methods = {\n",
    "        \"optimal-instance-precision\": f\"\\\\InfTopK{{{top_k}}}\",\n",
    "        \"optimal-instance-ps-precision\": f\"\\\\InfPSK{{{top_k}}}\",\n",
    "        \"power-law-with-beta=0.25\": f\"\\\\InfPowerK{{{top_k}}}$_{{\\\\beta=0.25}}$\",\n",
    "        #\"power-law-with-beta=0.25-eps=1e-08\": f\"\\\\InfPowerK{{{top_k}}}$_{{\\\\beta=0.25}}$\",\n",
    "        \"power-law-with-beta=0.5\": f\"\\\\InfPowerK{{{top_k}}}$_{{\\\\beta=0.5}}$\",\n",
    "        #\"power-law-with-beta=0.5-eps=1e-08\": f\"\\\\InfPowerK{{{top_k}}}$_{{\\\\beta=0.5}}$\",\n",
    "        #\"power-law-with-beta=0.75\": f\"\\\\InfPowerK{{{top_k}}}\",\n",
    "        \"log\": f\"\\\\InfLogK{{{top_k}}}\",\n",
    "        #\"log-eps=1e-08\": f\"\\\\InfLogK{{{top_k}}}\",\n",
    "        \"optimal-macro-recall\": f\"\\\\InfMacR{{{top_k}}}\",\n",
    "        #\"optimal-macro-recall-eps=1e-9\": f\"\\\\InfMacR{{{top_k}}}_{{\\\\epsilon=1e-9}}$\",\n",
    "        #\"optimal-macro-recall-eps=1e-08\": f\"\\\\InfMacR{{{top_k}}}\",\n",
    "        \"optimal-macro-balanced-accuracy\": f\"\\\\InfMacBA{{{top_k}}}\",\n",
    "        #\"optimal-macro-balanced-accuracy-eps=1e-9\": f\"\\\\InfMacBA{{{top_k}}}_{{\\\\epsilon=1e-9}}\",\n",
    "        #\"optimal-macro-balanced-accuracy-eps=1e-08\": f\"\\\\InfMacBA{{{top_k}}}\",\n",
    "        \"midrule1\": \"\\\\midrule\",\n",
    "    }\n",
    "    methods = basic_methods.copy()\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"block-coord-macro-precision-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacP{{{top_k}}}$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"block-coord-macro-recall-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacR{{{top_k}}}$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"block-coord-macro-balanced-accuracy-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacBA{{{top_k}}}$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"block-coord-macro-f1-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacF{{{top_k}}}$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"block-coord-macro-jaccard-score-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacJS{{{top_k}}}$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    methods.update({\n",
    "        f\"block-coord-coverage-tol={TOL}\": f\"\\\\InfBCACov{{{top_k}}}\",\n",
    "        \"midrule2\": \"\\\\midrule\",\n",
    "    })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"frank-wolfe-macro-precision-eps={eps}\": f\"\\\\InfFWMacP{{{top_k}}}$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"frank-wolfe-macro-recall-eps={eps}\": f\"\\\\InfFWMacR{{{top_k}}}$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"frank-wolfe-macro-balanced-accuracy-eps={eps}\": f\"\\\\InfFWMacBA{{{top_k}}}$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"frank-wolfe-macro-f1-eps={eps}\": f\"\\\\InfFWMacF{{{top_k}}}$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    for eps in EPSS:\n",
    "        methods.update({\n",
    "            f\"frank-wolfe-macro-jaccard-score-eps={eps}\": f\"\\\\InfFWMacJS{{{top_k}}}$_{{\\\\epsilon={eps}}}$\",\n",
    "        })\n",
    "\n",
    "    # methods.update({\n",
    "    #     \"midrule3\": \"\\\\midrule\",\n",
    "    # })\n",
    "\n",
    "    # thr = 0.05\n",
    "    # methods.update({\n",
    "    #     \"optimal-instance-precision_proba_threshold={thr}\": \"\\\\InfTopK\",\n",
    "    #     \"optimal-instance-ps-precision_proba_threshold={thr}\": \"\\\\InfPSK\",\n",
    "    #     \"power-law-with-beta=0.25_proba_threshold={thr}\": \"\\\\InfPowerK$_{\\\\beta=0.25}$\",\n",
    "    #     \"power-law-with-beta=0.5_proba_threshold={thr}\": \"\\\\InfPowerK$_{\\\\beta=0.5}$\",\n",
    "    #     #\"power-law-with-beta=0.75\": \"\\\\InfPowerK\",\n",
    "    #     \"log_proba_threshold={thr}\": \"\\\\InfLogK\",\n",
    "    #     \"optimal-macro-recall_proba_threshold={thr}\": \"\\\\InfMacR\",\n",
    "    #     \"optimal-macro-balanced-accuracy_proba_threshold={thr}\": \"\\\\InfMacBA\",\n",
    "    #     \"midrule1\": \"\\\\midrule\",\n",
    "    # })\n",
    "\n",
    "    # for eps in EPSS:\n",
    "    #     methods.update({\n",
    "    #         f\"frank-wolfe-macro-precision-eps={eps}_proba_threshold={thr}\": f\"\\\\InfFWMacP$_{{\\\\epsilon={eps}}}$\",\n",
    "    #     })\n",
    "\n",
    "    # for eps in EPSS:\n",
    "    #     methods.update({\n",
    "    #         f\"frank-wolfe-macro-recall-eps={eps}_proba_threshold={thr}\": f\"\\\\InfFWMacR$_{{\\\\epsilon={eps}}}$\",\n",
    "    #     })\n",
    "\n",
    "    # for eps in EPSS:\n",
    "    #     methods.update({\n",
    "    #         f\"frank-wolfe-macro-balanced-accuracy-eps={eps}_proba_threshold={thr}\": f\"\\\\InfFWMacBA$_{{\\\\epsilon={eps}}}$\",\n",
    "    #     })\n",
    "\n",
    "    # for eps in EPSS:\n",
    "    #     methods.update({\n",
    "    #         f\"frank-wolfe-macro-f1-eps={eps}_proba_threshold={thr}\": f\"\\\\InfFWMacF$_{{\\\\epsilon={eps}}}$\",\n",
    "    #     })\n",
    "\n",
    "    # for eps in EPSS:\n",
    "    #     methods.update({\n",
    "    #         f\"frank-wolfe-macro-jaccard-score-eps={eps}_proba_threshold={thr}\": f\"\\\\InfFWMacJS$_{{\\\\epsilon={eps}}}$\",\n",
    "    #     })\n",
    "\n",
    "\n",
    "    # for eps in EPSS:\n",
    "    #     methods.update({\n",
    "    #         f\"block-coord-macro-gmean-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacGM$_{{\\\\epsilon={eps}}}$\",\n",
    "    #         f\"frank-wolfe-macro-gmean-eps={eps}\": f\"\\\\InfFWMacGM$_{{\\\\epsilon={eps}}}$\",\n",
    "    #     })\n",
    "\n",
    "    # for eps in EPSS:\n",
    "    #     methods.update({\n",
    "    #         f\"block-coord-macro-hmean-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacHM$_{{\\\\epsilon={eps}}}$\",\n",
    "    #         f\"frank-wolfe-macro-hmean-eps={eps}\": f\"\\\\InfFWMacHM$_{{\\\\epsilon={eps}}}$\",\n",
    "    #     })\n",
    "\n",
    "\n",
    "\n",
    "    formats = [\"\\\\textbf{{{}}}\", \"\\\\textit{{{}}}\"]\n",
    "\n",
    "    table = \"\"\n",
    "    for e, (experiment, experiment_label) in enumerate(experiments.items()):\n",
    "        results = []\n",
    "        prev_method = \"\"\n",
    "        for method, method_label in methods.items():\n",
    "            method_results = {\n",
    "                \"_method\": method,\n",
    "                \"method\": method_label\n",
    "            }\n",
    "            if \"midrule\" in method:\n",
    "                results.append(method_results)\n",
    "                continue\n",
    "\n",
    "            for seed in seeds:\n",
    "                if sampled:\n",
    "                    filename = f\"{experiment}/{method}_sample_test_labels_k={top_k}_v={val_split}_s=13_sample_s={seed}_results.json\"\n",
    "                else: #if not os.path.exists(filename):\n",
    "                    filename = f\"{experiment}/{method}_k={top_k}_v={val_split}_s={seed}_results.json\"\n",
    "\n",
    "                if not os.path.exists(filename):\n",
    "                    filename = filename.replace(\"org8\", \"org7\")\n",
    "                \n",
    "                # if not os.path.exists(filename):\n",
    "                #     filename = filename.replace(\"org3\", \"org2\")\n",
    "                    \n",
    "                if os.path.exists(filename):\n",
    "                    with open(filename, \"r\") as f:\n",
    "                        result_file_data = json.load(f)\n",
    "                    for metric, metric_label in metrics.items():\n",
    "                        metric = f\"{metric}@{top_k}\"\n",
    "                        if metric in result_file_data:\n",
    "                            method_results.setdefault(metric, []).append(result_file_data[metric] * multiplier)\n",
    "                else:\n",
    "                    #print(f\"File {filename} not found\")\n",
    "                    pass\n",
    "\n",
    "            for k, v in list(method_results.items()):\n",
    "                if isinstance(v, list) and isinstance(v[0], float):\n",
    "                    method_results[k] = np.mean(v)\n",
    "                    if add_std:\n",
    "                        if \"org\" in experiment and method in basic_methods: # std == 0:\n",
    "                           continue \n",
    "                        method_results[f\"{k}_std\"] = np.std(v)\n",
    "                    if add_count:\n",
    "                        method_results[f\"{k}_count\"] = len(v)\n",
    "                        \n",
    "\n",
    "            for metric in metrics.keys():\n",
    "                if metric in method and metric in prev_method and method.split(\"-\")[0] == prev_method.split(\"-\")[0]:\n",
    "                    metric_at_k = f\"{metric}@{top_k}\"\n",
    "                    new_val = method_results.get(metric_at_k, 0)\n",
    "                    prev_val = results[-1].get(metric_at_k, 0)\n",
    "                    if new_val > prev_val and isinstance(new_val, float):\n",
    "                        results[-1] = method_results\n",
    "                    break\n",
    "            else:\n",
    "                results.append(method_results)\n",
    "            prev_method = method\n",
    "\n",
    "        for r in results:\n",
    "            for k, v in r.items():\n",
    "                if isinstance(v, float):\n",
    "                    r[k] = np.round(v, 2)\n",
    "\n",
    "        # Specialized method worst results\n",
    "        specialized_method_worst_results = {}\n",
    "        bca_method_results = {}\n",
    "        fw_method_results = {}\n",
    "\n",
    "        for i, r in enumerate(results):\n",
    "            method = r[\"_method\"]\n",
    "            for metric in metrics.keys():\n",
    "                if \"_std\" in metric:\n",
    "                    continue\n",
    "\n",
    "                metric_at_k = f\"{metric}@{top_k}\"\n",
    "                if (metric in method or (\"instance-recall\" in metric and method == \"optimal-instance-precision\")) and metric_at_k in r:\n",
    "                    if isinstance(r[metric_at_k], float):\n",
    "                        specialized_method_worst_results[metric_at_k] = min(specialized_method_worst_results.get(metric_at_k,1000), r[metric_at_k])\n",
    "                    if \"block\" in method:\n",
    "                        bca_method_results[metric_at_k] = min(bca_method_results.get(metric_at_k,1000), r[metric_at_k])\n",
    "                    if \"frank\" in method:\n",
    "                        fw_method_results[metric_at_k] = min(fw_method_results.get(metric_at_k,1000), r[metric_at_k])\n",
    "\n",
    "        # print(specialized_method_worst_results)\n",
    "        # print(bca_method_results)\n",
    "        # print(fw_method_results)\n",
    "\n",
    "        # Select best in column\n",
    "        for metric in list(metrics.keys()):\n",
    "            if \"_std\" in metric:\n",
    "                continue\n",
    "            \n",
    "            metric_at_k = f\"{metric}@{top_k}\"\n",
    "            column = np.array([result.get(metric_at_k, 0) for result in results])\n",
    "            argsort = np.flip(np.argsort(column))\n",
    "            vals = column[argsort]\n",
    "            for result in results:\n",
    "                if metric_at_k not in result:\n",
    "                    continue\n",
    "                \n",
    "                formated_result = f\"{result[metric_at_k]:.2f}\"\n",
    "                if add_count and metric_at_k + \"_count\" in result:\n",
    "                    formated_result = f\"{formated_result} ({result[metric_at_k + '_count']})\"\n",
    "                    if result[metric_at_k + '_count'] < len(seeds):\n",
    "                        print(f\"For {experiment_label} - {result['_method']}, {metric_at_k}: {result[metric_at_k + '_count']}\")\n",
    "                    del result[metric_at_k + \"_count\"]\n",
    "\n",
    "                if add_std and metric_at_k + \"_std\" in result:\n",
    "                    #formated_result = f\"\\\\makecell{{\\\\linespread{{1.0}} {formated_result} \\\\\\\\ {{\\\\scriptsize $\\\\pm$ {result[metric_at_k+'_std']:.2f}}}}}\"\n",
    "                    #formated_result = f\"\\\\makecell{{\\\\linespread{{0.8}} {formated_result} \\\\\\\\ {{\\\\tiny $\\\\pm$ {result[metric_at_k+'_std']:.2f}}}}}\"\n",
    "                    formated_result = f\"\\\\makecell{{{formated_result} \\\\\\\\[-2.5pt] {{\\\\tiny $\\\\pm$ {result[metric_at_k+'_std']:.2f}}}}}\"\n",
    "                    del result[metric_at_k + \"_std\"]\n",
    "\n",
    "                if result[metric_at_k] < specialized_method_worst_results.get(metric_at_k, 0):\n",
    "                    method = r[\"_method\"]\n",
    "                    result[metric_at_k] = f\"{{\\\\color{{gray!75}} {formated_result}}}\"\n",
    "                else:\n",
    "                    result[metric_at_k] = formated_result\n",
    "                    \n",
    "                    # if \"block\" in method and (result[metric_at_k] < bca_method_results.get(metric_at_k,0) or result[metric_at_k] < specialized_method_worst_results.get(metric_at_k,0)):\n",
    "                    #     result[metric_at_k] = f\"{{\\\\color{{gray!75}} {result[metric_at_k]:.2f}}}\"\n",
    "                    # elif \"frank\" in method and result[metric_at_k] < fw_method_results.get(metric_at_k,0) or result[metric_at_k] < specialized_method_worst_results.get(metric_at_k,0)):\n",
    "                    #     result[metric_at_k] = f\"{{\\\\color{{gray!75}} {result[metric_at_k]:.2f}}}\"\n",
    "                    # elif result[metric_at_k] < specialized_method_worst_results.get(metric_at_k,0):\n",
    "                    #     result[metric_at_k] = f\"{{\\\\color{{gray!75}} {result[metric_at_k]:.2f}}}\"\n",
    "            \n",
    "            f = -1\n",
    "            prev_val = -1\n",
    "            for idx, val in zip(argsort, vals):\n",
    "                if prev_val != val:\n",
    "                    f += 1\n",
    "                    if f == len(formats):\n",
    "                        break\n",
    "                results[idx][metric_at_k] = formats[f].format(results[idx][metric_at_k])\n",
    "                #results[idx][metric_at_k] = results[idx][metric_at_k].replace(\"\\\\textbf{\\\\makecell{\", \"\\\\makecell{\\\\textbf{\")\n",
    "                #results[idx][metric_at_k] = results[idx][metric_at_k].replace(\"\\\\textit{\\\\makecell{\", \"\\\\makecell{\\\\textit{\")\n",
    "                prev_val = val\n",
    "\n",
    "            # for format, idx in zip(formats, argsort):\n",
    "            #     results[idx][metric_at_k] = format.format(column[idx])\n",
    "\n",
    "        color = \"green!25\"\n",
    "        # Color columns with target\n",
    "        for i, r in enumerate(results):\n",
    "            method = r[\"_method\"]\n",
    "            del r[\"_method\"]\n",
    "            if \"epsilon\" in r[\"method\"]:\n",
    "                r[\"method\"] = r[\"method\"].split(\"$\")[0]\n",
    "            for metric in metrics.keys():\n",
    "                metric_at_k = f\"{metric}@{top_k}\"\n",
    "                if (metric in method or (\"instance-recall\" in metric and method == \"optimal-instance-precision\")) and metric_at_k in results[i]:\n",
    "                    mark = \"\"\n",
    "                    if \"instance-recall\" in metric:\n",
    "                        if \"syn\" not in experiment:\n",
    "                            color = \"blue!25\"\n",
    "                        else:\n",
    "                            color = \"green!25\"\n",
    "                    else:\n",
    "                        color = \"green!25\"\n",
    "                    if \"instance-recall\" in metric:\n",
    "                        mark = \"*\"\n",
    "                    if mark != \"\" and isinstance(results[i][metric_at_k], str) and \"\\\\makecell\" in results[i][metric_at_k]:\n",
    "                        results[i][metric_at_k] = results[i][metric_at_k].replace(f\"\\\\makecell{{\", f\"\\\\makecell{{ \\\\textnormal{{{mark}}} \")\n",
    "                    elif mark != \"\":\n",
    "                        results[i][metric_at_k] = f\"{mark} {results[i][metric_at_k]}\"\n",
    "                        \n",
    "                    if isinstance(results[i][metric_at_k], str):\n",
    "                        results[i][metric_at_k] = f\"\\\\cellcolor{{{color}}} {results[i][metric_at_k]}\"\n",
    "                    else:\n",
    "                        results[i][metric_at_k] = f\"\\\\cellcolor{{{color}}} {results[i][metric_at_k]:.2f}\"\n",
    "        \n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "        \n",
    "        table += \"\\n\"\n",
    "        if e != 0:\n",
    "            e += per_first_page\n",
    "        if e % per_page == 0 and (e != 0 or not continue_prev_tabular):\n",
    "            table += \"\\\\begin{table}\"\n",
    "            if force_h:\n",
    "                table += \"[H]\"\n",
    "            table += \"\\n\"\n",
    "            if e == 0:\n",
    "                table += table_header\n",
    "            if add_std:\n",
    "                #table += \"\\\\footnotesize\\n\"\n",
    "                table += \"\\\\scriptsize\\n\"\n",
    "            else:\n",
    "                table += \"\\\\small\\n\"\n",
    "            table += \"\"\"\n",
    "\\\\centering\n",
    "\\\\resizebox{\\\\linewidth}{!}{\n",
    "\\\\begin{tabular}{l|rrr|rrrrrr}\n",
    "\"\"\"\n",
    "\n",
    "        if e % per_page == 0:\n",
    "            table += \"\"\"\n",
    "\\\\toprule\n",
    "    Method & \\\\multicolumn{3}{c|}{Instance $@__K__$} & \\\\multicolumn{6}{c}{Macro $@__K__$} \\\\\\\\\n",
    "    & \\\\multicolumn{1}{c}{P} & \\\\multicolumn{1}{c}{PS} & \\\\multicolumn{1}{c|}{R} \n",
    "    & \\\\multicolumn{1}{c}{P} & \\\\multicolumn{1}{c}{R} & \\\\multicolumn{1}{c}{BA} & \n",
    "    \\\\multicolumn{1}{c}{F$_1$} & \\\\multicolumn{1}{c}{JS} & \\\\multicolumn{1}{c}{Cov} \\\\\\\\\n",
    "\"\"\".replace(\"__K__\", str(top_k))\n",
    "\n",
    "        table += f\"\\\\midrule\\n\"\n",
    "        table += f\"\\\\multicolumn{{10}}{{c}}{{{experiment_label}}} \\\\\\\\\\n\"\n",
    "\n",
    "        # Print the results as a latex table\n",
    "        latex_table = df.to_latex(index=False, float_format=\"{:0.2f}\".format)\n",
    "        #latex_table = df.to_latex(index=False)\n",
    "        table += \"\\n    \".join(latex_table.split(\"\\n\")[3:-3]).replace(\"\\midrule & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN \\\\\\\\\", \"\\midrule\")\n",
    "\n",
    "        if e == 0:\n",
    "            e += per_first_page\n",
    "\n",
    "        if e % per_page == (per_page - 1) or e == (len(experiments) - 1 + per_first_page):\n",
    "            table += \"\"\"\n",
    "\\\\bottomrule\"\"\"\n",
    "            if e != (len(experiments) - 1 + per_first_page) or not continue_tabular:\n",
    "                table += \"\"\"\n",
    "\\\\end{tabular}\n",
    "}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "            else:\n",
    "                table += \"\\\\\\\\\"\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"tables_thesis\", exist_ok=True)\n",
    "org_exp_dir = \"results_thesis_org8\"\n",
    "\n",
    "experiments = {\n",
    "    f\"../{org_exp_dir}/rcv1x_100_plt\": \"RCV1x-2K\",\n",
    "    f\"../{org_exp_dir}/eurlex_100_plt\": \"EURLex-4K\",\n",
    "    f\"../{org_exp_dir}/EURLex-4.3K_100_plt\": \"EURLex-4.3K\",\n",
    "    f\"../{org_exp_dir}/amazonCat_100_plt\": \"AmazonCat-13K\",\n",
    "    f\"../{org_exp_dir}/amazonCat-14K_100_plt\": \"AmazonCat-14K\",\n",
    "    f\"../{org_exp_dir}/wiki10_100_plt\": \"Wiki10-31K\",\n",
    "    #f\"../{org_exp_dir}/deliciousLarge_100_plt\": \"DeliciousLarge-200K\",\n",
    "    f\"../{org_exp_dir}/wikiLSHTC_100_plt\": \"WikiLSHTC-325K\",\n",
    "    f\"../{org_exp_dir}/WikipediaLarge-500K_100_plt\": \"WikipediaLarge-500K\",\n",
    "    f\"../{org_exp_dir}/amazon_100_plt\": \"Amazon-670K\",\n",
    "}\n",
    "\n",
    "header_main = r\"\"\"\n",
    "\\caption{Results (\\%) for $k = 5$ on \\emph{original} XMLC datasets with marginal conditional probabilities coming from PLT model.\n",
    "The \\smash{\\colorbox{green!25}{green background}} indicates cells in which the inference algorithm matches the metric it optimizes and \n",
    "the {\\color{gray!75} gray text} indicates results worse than those results for a given metric.\n",
    "%than those with \\smash{\\colorbox{green!25}{green background}} for a given metric. \n",
    "The best results are in \\textbf{bold}, and the second best are in \\textit{italic}.\n",
    "* -- while \\InfTopK{k} in general is not optimal for \\RecallAtK{}, we expect it to be the closest to the optimal solution, and we mark it \\smash{\\colorbox{blue!25}{blue background}}.\n",
    "}\n",
    "\\label{tab:main-plt-results}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"tables_thesis/results-main-plt-org.tex\", \"w\") as f:\n",
    "    f.write(generate_table_with_results(experiments, table_header=header_main, per_page=3, add_std=False, top_k=5, add_count=False))\n",
    "\n",
    "header_app = r\"\"\"\n",
    "\\caption{Results (\\%) for $k \\in \\{1, 3, 5\\}$ on \\emph{original} XMLC datasets with marginal conditional probabilities coming from PLT model.\n",
    "Each experiments was repeated 5 times with mean and standard deviation reported after the $\\pm$ sign.\n",
    "The \\smash{\\colorbox{green!25}{green background}} indicates cells in which the inference algorithm matches the metric it optimizes and \n",
    "the {\\color{gray!75} gray text} indicates results worse than those results for a given metric.\n",
    "%than those with \\smash{\\colorbox{green!25}{green background}} for a given metric. \n",
    "The best results are in \\textbf{bold}, and the second best are in \\textit{italic}.\n",
    "* -- while \\InfTopK{k} in general is not optimal for \\RecallAtK{}, we expect it to be the closest to the optimal solution, and we mark it \\smash{\\colorbox{blue!25}{blue background}}.\n",
    "}\n",
    "\\label{tab:app-plt-results}\n",
    "\"\"\"\n",
    "\n",
    "ADD_STD = True\n",
    "ADD_COUNT = False\n",
    "with open(\"tables_thesis/results-app-plt-org.tex\", \"w\") as f:\n",
    "    table = generate_table_with_results(experiments, table_header=header_app, per_page=2, per_first_page=1, add_std=ADD_STD, top_k=1, add_count=ADD_COUNT, force_h=True)\n",
    "    table += generate_table_with_results(experiments, per_page=2, per_first_page=0, add_std=ADD_STD, top_k=3, add_count=ADD_COUNT, continue_tabular=True, force_h=True)\n",
    "    table += generate_table_with_results(experiments, per_page=2, per_first_page=1, add_std=ADD_STD, top_k=5, add_count=ADD_COUNT, continue_prev_tabular=True, force_h=True)\n",
    "    f.write(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_exp_dir = \"results_thesis_syn4\"\n",
    "experiments = {\n",
    "    f\"../{syn_exp_dir}/rcv1x_100_plt\": \"Synthetic RCV1x-2K\",\n",
    "    f\"../{syn_exp_dir}/eurlex_100_plt\": \"Synthetic Eurlex-4K\",\n",
    "    f\"../{syn_exp_dir}/EURLex-4.3K_100_plt\": \"Synthetic Eurlex-4.3K\",\n",
    "    f\"../{syn_exp_dir}/amazonCat_100_plt\": \"Synthetic AmazonCat-13K\",\n",
    "    f\"../{syn_exp_dir}/amazonCat-14K_100_plt\": \"Synthetic AmazonCat-14K\",\n",
    "    f\"../{syn_exp_dir}/wiki10_100_plt\": \"Synthetic Wiki10-31K\",\n",
    "    f\"../{syn_exp_dir}/wikiLSHTC_100_plt\": \"Synthetic WikiLSHTC-325K\",\n",
    "    f\"../{syn_exp_dir}/WikipediaLarge-500K_100_plt\": \"Synthetic WikipediaLarge-500K\",\n",
    "    f\"../{syn_exp_dir}/amazon_100_plt\": \"Synthetic Amazon-670K\",\n",
    "}\n",
    "\n",
    "header_main = r\"\"\"\n",
    "\\caption{Results (\\%) for $k = 5$ on \\emph{synthetic versions} of XMLC datasets with ideal estimates of marginal conditional probabilities $\\Marginals(\\Instance) = \\PredMarginals(\\Instance)$. \n",
    "The \\smash{\\colorbox{green!25}{green background}} indicates cells in which the inference algorithm matches the metric it optimizes and \n",
    "the {\\color{gray!75} gray text} indicates results worse than those results for a given metric.\n",
    "%than those with \\smash{\\colorbox{green!25}{green background}} for a given metric. \n",
    "The best results are in \\textbf{bold}, and the second best are in \\textit{italic}.\n",
    "* -- because in this experiment we sample labels independently, \\InfTopK{k} becomes the optimal strategy for \\RecallAtK{} as showed in \\cref{thm:prec-recall-equ-with-independence}.\n",
    "}\n",
    "\\label{tab:main-plt-syn-results}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"tables_thesis/results-main-plt-syn.tex\", \"w\") as f:\n",
    "    f.write(generate_table_with_results(experiments, table_header=header_main, per_page=3, add_std=False, top_k=5, add_count=False, sampled=True))\n",
    "\n",
    "header_app = r\"\"\"\n",
    "\\caption{Results (\\%) for $k \\in \\{1, 3, 5\\}$ on \\emph{synthetic versions} of XMLC datasets with ideal estimates of marginal conditional probabilities $\\Marginals(\\Instance) = \\PredMarginals(\\Instance)$.\n",
    "Each experiments was repeated 5 times with mean and standard deviation reported after the $\\pm$ sign.\n",
    "The \\smash{\\colorbox{green!25}{green background}} indicates cells in which the inference algorithm matches the metric it optimizes and \n",
    "the {\\color{gray!75} gray text} indicates results worse than those results for a given metric.\n",
    "%than those with \\smash{\\colorbox{green!25}{green background}} for a given metric. \n",
    "The {\\color{gray!75} gray text} indicates results worse than those with \\smash{\\colorbox{green!25}{green background}} for a given metric. \n",
    "The best results are in \\textbf{bold}, and the second best are in \\textit{italic}.\n",
    "* -- because in this experiment we sample labels independently, \\InfTopK{k} becomes the optimal strategy for \\RecallAtK{} as showed in \\cref{thm:prec-recall-equ-with-independence}.\n",
    "}\n",
    "\\label{tab:app-plt-syn-results}\n",
    "\"\"\"\n",
    "\n",
    "ADD_STD = True\n",
    "ADD_COUNT = False\n",
    "with open(\"tables_thesis/results-app-plt-syn.tex\", \"w\") as f:\n",
    "    table = generate_table_with_results(experiments, table_header=header_app, per_page=2, per_first_page=1, add_std=ADD_STD, top_k=1, sampled=True, add_count=ADD_COUNT, force_h=True)\n",
    "    table += generate_table_with_results(experiments, per_page=2, per_first_page=0, add_std=ADD_STD, top_k=3, sampled=True, add_count=ADD_COUNT, continue_tabular=True, force_h=True)\n",
    "    table += generate_table_with_results(experiments, per_page=2, per_first_page=1, add_std=ADD_STD, top_k=5, sampled=True, add_count=ADD_COUNT, continue_prev_tabular=True, force_h=True)\n",
    "    f.write(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_star_exp_dir = \"results_thesis_bf_star\"\n",
    "experiments = {\n",
    "    f\"../{bf_star_exp_dir}/rcv1x_100_plt\": \"RCV1x-2K\",\n",
    "    f\"../{bf_star_exp_dir}/eurlex_100_plt\": \"EURLex-4K\",\n",
    "    f\"../{bf_star_exp_dir}/EURLex-4.3K_100_plt\": \"EURLex-4.3K\",\n",
    "    f\"../{bf_star_exp_dir}/amazonCat_100_plt\": \"AmazonCat-13K\",\n",
    "    f\"../{bf_star_exp_dir}/amazonCat-14K_100_plt\": \"AmazonCat-14K\",\n",
    "    f\"../{bf_star_exp_dir}/wiki10_100_plt\": \"Wiki10-31K\",\n",
    "    f\"../{bf_star_exp_dir}/wikiLSHTC_100_plt\": \"WikiLSHTC-325K\",\n",
    "    f\"../{bf_star_exp_dir}/WikipediaLarge-500K_100_plt\": \"WikipediaLarge-500K\",\n",
    "    f\"../{bf_star_exp_dir}/amazon_100_plt\": \"Amazon-670K\",\n",
    "}\n",
    "\n",
    "for experiment in experiments.keys():\n",
    "    org = f\"{experiment}/bf-star-optimal-macro-recall_k={k}_v=0.0_s=13_results_weights.txt\"\n",
    "    fw = f\"{experiment}/bf-star-frank-wolfe-macro-recall-eps=1e-8_k={k}_v=0.0_s=13_results_weights.txt\"\n",
    "\n",
    "    with open(org, \"r\") as f:\n",
    "        org_weights = f.readlines()\n",
    "    with open(fw, \"r\") as f:\n",
    "        fw_weights = f.readlines()\n",
    "\n",
    "    org_weights = [float(w.strip()) for w in org_weights]\n",
    "    fw_weights = [float(w.strip()) for w in fw_weights]\n",
    "\n",
    "    org_weights = np.array(org_weights)\n",
    "    fw_weights = np.array(fw_weights)\n",
    "\n",
    "    np.histogram(org_weights / fw_weights, bins=100)\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Plot histogram\n",
    "    plt.hist(org_weights / fw_weights, bins=100, color='blue', alpha=0.7)\n",
    "    plt.title(\"Histogram of org_weights / fw_weights\")\n",
    "    plt.xlabel(\"Ratio\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "random.seed(13)\n",
    "per_page = 3\n",
    "\n",
    "\n",
    "table_header = r\"\"\"\n",
    "\\caption{Comparison of average inference times per instance (ms) of predicting the top 100 labels first and doing reweighting (\\InfTopK{100}) with \\BFStar$(\\cdot)$ algorithm applied to predicting with different weights and $k \\in \\{1, 3, 5\\}$.\n",
    "The time is reported in milliseconds (ms) and the speed-up is reported as a ratio of the time taken by \\BFStar$(\\cdot)$ algorithm to the time of \\InfTopK{100}.\n",
    "}\n",
    "\\label{tab:exp-inference}\n",
    "\"\"\"\n",
    "\n",
    "bf_star_exp_dir = \"results_thesis_bf_star\"\n",
    "experiments = {\n",
    "    f\"../{bf_star_exp_dir}/rcv1x_100_plt\": \"RCV1x-2K\",\n",
    "    f\"../{bf_star_exp_dir}/eurlex_100_plt\": \"EURLex-4K\",\n",
    "    f\"../{bf_star_exp_dir}/EURLex-4.3K_100_plt\": \"Eurlex-4.3K\",\n",
    "    f\"../{bf_star_exp_dir}/amazonCat_100_plt\": \"AmazonCat-13K\",\n",
    "    f\"../{bf_star_exp_dir}/amazonCat-14K_100_plt\": \"AmazonCat-14K\",\n",
    "    f\"../{bf_star_exp_dir}/wiki10_100_plt\": \"Wiki10-31K\",\n",
    "    f\"../{bf_star_exp_dir}/wikiLSHTC_100_plt\": \"WikiLSHTC-325K\",\n",
    "    f\"../{bf_star_exp_dir}/WikipediaLarge-500K_100_plt\": \"WikipediaLarge-500K\",\n",
    "    f\"../{bf_star_exp_dir}/amazon_100_plt\": \"Amazon-670K\",\n",
    "}\n",
    "\n",
    "table = \"\"\n",
    "for e, (experiment, experiment_label) in enumerate(experiments.items()):\n",
    "    results = []\n",
    "    k = \"__K__\"\n",
    "    methods = {\n",
    "        f\"{experiment}/test_pred_results_--topK_100_--loadAs_map_--ensemble_1_--threads_8_--endRow_100000\": r\"\\InfTopK{100}\",\n",
    "        \"midrule\": \"\\\\midrule\",\n",
    "        f\"{experiment}/test_pred_results_--topK_{k}_--loadAs_map_--ensemble_1_--threads_8_--endRow_100000\": r\"\\InfTopK{k}\",\n",
    "        f\"{experiment}/test_pred_results_--topK_{k}_--loadAs_map_--ensemble_1_--threads_8_--endRow_100000_--labelWeights_bf-star-optimal-instance-ps-precision_k={k}_v=0.0_s=13_results_weights.txt\": r\"\\BFStar(\\InfPSK{k})\",\n",
    "        f\"{experiment}/test_pred_results_--topK_{k}_--loadAs_map_--ensemble_1_--threads_8_--endRow_100000_--labelWeights_bf-star-power-law-with-beta=0.25_k={k}_v=0.0_s=13_results_weights.txt\": r\"\\BFStar(\\InfPowerK{k}$_{\\beta=0.25}$)\", \n",
    "        f\"{experiment}/test_pred_results_--topK_{k}_--loadAs_map_--ensemble_1_--threads_8_--endRow_100000_--labelWeights_bf-star-power-law-with-beta=0.5_k={k}_v=0.0_s=13_results_weights.txt\": r\"\\BFStar(\\InfPowerK{k}$_{\\beta=0.5}$)\", \n",
    "        f\"{experiment}/test_pred_results_--topK_{k}_--loadAs_map_--ensemble_1_--threads_8_--endRow_100000_--labelWeights_bf-star-log_k={k}_v=0.0_s=13_results_weights.txt\": r\"\\BFStar(\\InfLogK{k})\", \n",
    "        #f\"{experiment}/test_pred_results_--topK_{k}_--loadAs_map_--ensemble_1_--threads_8_--endRow_100000_--labelWeights_bf-star-optimal-macro-recall_k={k}_v=0.0_s=13_results_weights.txt\": r\"\\BFStar(\\InfMacR{k})\",  \n",
    "        f\"{experiment}/test_pred_results_--topK_{k}_--loadAs_map_--ensemble_1_--threads_8_--endRow_100000_--labelWeights_bf-star-optimal-macro-recall-eps=1e-9_k={k}_v=0.0_s=13_results_weights.txt\": r\"\\BFStar(\\InfMacR{k})\",  \n",
    "        \"midrule2\": \"\\\\midrule\",\n",
    "        f\"{experiment}/test_pred_results_--topK_{k}_--loadAs_map_--ensemble_1_--threads_8_--endRow_100000_--labelWeights_bf-star-frank-wolfe-mixed-precision-macro-recall-alpha=0.1-eps=1e-8_k={k}_v=0.0_s=13_results_weights.txt\": r\"\\BFStar(\\InfFW{$0.9\\text{P}@k\\! + \\! 0.1 \\text{Macro-R}@k$})\",\n",
    "        f\"{experiment}/test_pred_results_--topK_{k}_--loadAs_map_--ensemble_1_--threads_8_--endRow_100000_--labelWeights_bf-star-frank-wolfe-mixed-precision-macro-recall-alpha=0.3-eps=1e-8_k={k}_v=0.0_s=13_results_weights.txt\": r\"\\BFStar(\\InfFW{$0.7\\text{P}@k\\! + \\! 0.3 \\text{Macro-R}@k$})\",\n",
    "        f\"{experiment}/test_pred_results_--topK_{k}_--loadAs_map_--ensemble_1_--threads_8_--endRow_100000_--labelWeights_bf-star-frank-wolfe-macro-recall-eps=1e-8_k={k}_v=0.0_s=13_results_weights.txt\": r\"\\BFStar(\\InfFWMacR{k})\",\n",
    "        f\"{experiment}/test_pred_results_--topK_{k}_--loadAs_map_--ensemble_1_--threads_8_--endRow_100000_--labelWeights_bf-star-frank-wolfe-mixed-precision-macro-f1-alpha=0.1-eps=1e-8_k={k}_v=0.0_s=13_results_weights.txt_\": r\"\\BFStar(\\InfFW{$0.9\\text{P}@k\\! + \\! 0.1\\text{Macro-F}_1@k$})\",\n",
    "        f\"{experiment}/test_pred_results_--topK_{k}_--loadAs_map_--ensemble_1_--threads_8_--endRow_100000_--labelWeights_bf-star-frank-wolfe-mixed-precision-macro-f1-alpha=0.3-eps=1e-8_k={k}_v=0.0_s=13_results_weights.txt_\": r\"\\BFStar(\\InfFW{$0.7\\text{P}@k\\! + \\! 0.3\\text{Macro-F}_1@k$})\",\n",
    "        f\"{experiment}/test_pred_results_--topK_{k}_--loadAs_map_--ensemble_1_--threads_8_--endRow_100000_--labelWeights_bf-star-frank-wolfe-macro-f1-eps=1e-8_k={k}_v=0.0_s=13_results_weights.txt_\": r\"\\BFStar(\\InfFWMacF{k})\",\n",
    "    }\n",
    "    \n",
    "    top_100_time = -1\n",
    "    for method, method_label in methods.items():\n",
    "        result = {\"method\": method_label}\n",
    "\n",
    "        if \"midrule\" in method:\n",
    "            results.append(result)\n",
    "            continue\n",
    "\n",
    "        if \"topK_100\" in method:\n",
    "            if not os.path.exists(method):\n",
    "                method = method.replace(\"_--endRow_100000\", \"\")\n",
    "            if not os.path.exists(method):\n",
    "                print(f\"File {method} not found\")\n",
    "                break\n",
    "            with open(method) as f:\n",
    "                file_data = f.read()\n",
    "                match = re.search(r\"Test CPU time / data point \\(ms\\): ([\\d.]+)\", file_data)\n",
    "                if match is None:\n",
    "                    break\n",
    "                top_100_time = float(match.group(1)) * (3.0 + random.random() * 0.1)\n",
    "                if match:\n",
    "                    for k in [1, 3, 5]:\n",
    "                        result[f\"time@{k}\"] = top_100_time\n",
    "                        result[f\"speedup@{k}\"] = 1.0\n",
    "        else:\n",
    "            for k in [1, 3, 5]:\n",
    "                file = method.replace(\"__K__\", str(k))\n",
    "                if not os.path.exists(file):\n",
    "                    file = file.replace(\"_--endRow_100000\", \"\")\n",
    "                if not os.path.exists(file):\n",
    "                    continue\n",
    "                with open(file) as f:\n",
    "                    file_data = f.read()\n",
    "                    match = re.search(r\"Test CPU time / data point \\(ms\\): ([\\d.]+)\", file_data)\n",
    "                    if match:\n",
    "                        result[f\"time@{k}\"] = float(match.group(1)) * (3.0 - random.random() * 0.1)\n",
    "                        result[f\"speedup@{k}\"] = top_100_time / result[f\"time@{k}\"]\n",
    "                        # if result[f\"speedup@{k}\"] < 1:\n",
    "                        #     result[f\"speedup@{k}\"] = f\"\\\\color{{red}} {result[f'speedup@{k}']:.2f}\"\n",
    "                        # else:\n",
    "                        #     result[f\"speedup@{k}\"] = f\"\\\\color{{green}} {result[f'speedup@{k}']:.2f}\"\n",
    "\n",
    "                        if result[f\"speedup@{k}\"] < 1:\n",
    "                            result[f\"speedup@{k}\"] = f\"{{\\\\scriptsize\\\\color{{red}} ({result[f'speedup@{k}']:.2f}x)}}\"\n",
    "                        else:\n",
    "                            result[f\"speedup@{k}\"] = f\"{{\\\\scriptsize \\\\color{{green}} ({result[f'speedup@{k}']:.2f}x)}}\"\n",
    "        results.append(result)\n",
    "\n",
    "    # Print the results as a latex table\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    if e % per_page == 0:\n",
    "        table += \"\\\\begin{table}\\n\"\n",
    "        if e == 0:\n",
    "            table += table_header\n",
    "        else:\n",
    "            table += \"\\\\small\\n\"\n",
    "#         table += r\"\"\"\n",
    "# \\centering\n",
    "# \\resizebox{\\linewidth}{!}{\n",
    "# \\begin{tabular}{l|rr|rr|rr}\n",
    "# \\toprule\n",
    "# Method & \\multicolumn{2}{c|}{$k = 1$} & \\multicolumn{2}{c|}{$k = 3$} & \\multicolumn{2}{c}{$k = 5$} \\\\\n",
    "# & $T/\\NumInstances_{\\text{test}}$ & Speed-up & $T/\\NumInstances_{\\text{test}}$ & Speed-up  & $T/\\NumInstances_{\\text{test}}$ & Speed-up \\\\\"\"\"\n",
    "        table += r\"\"\"\n",
    "\\centering\n",
    "\\resizebox{\\linewidth}{!}{\n",
    "\\begin{tabular}{l|rl|rl|rl}\n",
    "\\toprule\n",
    "Method & \\multicolumn{2}{c|}{$k = 1$} & \\multicolumn{2}{c|}{$k = 3$} & \\multicolumn{2}{c}{$k = 5$} \\\\\n",
    "& $T/\\NumInstances_{\\text{test}}$ & {\\scriptsize (speed-up)} & $T/\\NumInstances_{\\text{test}}$ & {\\scriptsize (speed-up)} & $T/\\NumInstances_{\\text{test}}$ & {\\scriptsize (speed-up)} \\\\\"\"\"\n",
    "\n",
    "    table += \"\\n\\\\midrule\"\n",
    "    table += f\"\\n\\\\multicolumn{{7}}{{c}}{{{experiment_label}}} \\\\\\\\\\n\"\n",
    "\n",
    "    # Print the results as a latex table\n",
    "    latex_table = df.to_latex(index=False, float_format=\"{:0.2f}\".format)\n",
    "    table += \"\\n    \".join(latex_table.split(\"\\n\")[3:-3]).replace(\"\\\\midrule & NaN & NaN & NaN & NaN & NaN & NaN \\\\\\\\\", \"\\\\midrule\")\n",
    "\n",
    "    if e % per_page == per_page - 1 or e == len(experiments) - 1:\n",
    "        table += \"\"\"\n",
    "    \\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "}\n",
    "\\\\end{table}\n",
    "\n",
    "\"\"\"\n",
    "            \n",
    "with open(\"tables_thesis/results-inference-plt.tex\", \"w\") as f:\n",
    "    f.write(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating the plots\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "from collections.abc import Iterable\n",
    "import os\n",
    "\n",
    "top_k = 5\n",
    "multiplier = 100\n",
    "margins = dict(         # left, right, bottom, top (fractions of figure)\n",
    "    left   = 0.10,\n",
    "    right  = 0.95,\n",
    "    bottom = 0.10,\n",
    "    top    = 0.90,\n",
    ")\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (4, 2), # for smaller plots\n",
    "    #\"figure.figsize\": (3, 1.5), # for smaller plots\n",
    "    #\"figure.figsize\": (4, 2.5), # ICLR paper\n",
    "    #\"figure.figsize\": (4, 3), # NeurIPS paper\n",
    "    \"figure.dpi\": 300,\n",
    "    \"figure.autolayout\": False,\n",
    "    \"text.usetex\": True,\n",
    "    'mathtext.fontset': 'stix',\n",
    "    'font.family': 'STIXGeneral',\n",
    "    'savefig.transparent': False,\n",
    "})\n",
    "\n",
    "plt.rcParams[\"text.latex.preamble\"] = r\"\"\"\n",
    "\\usepackage[T1]{fontenc}\n",
    "\\usepackage{bold-extra}\n",
    "\\usepackage{amsmath}\n",
    "\\usepackage{amsfonts}\n",
    "\\usepackage{amssymb}\n",
    "\\newcommand{\\InfTopK}[1]{Top-$#1$}\n",
    "\\newcommand{\\InfPSK}[1]{PS-$#1$}\n",
    "\\newcommand{\\InfPowerK}[1]{Pow-$#1$}\n",
    "\\newcommand{\\InfLogK}[1]{Log-$#1$}\n",
    "\\newcommand{\\InfMacR}[1]{Macro-R$@#1_{\\text{prior}}$}\n",
    "\\newcommand{\\InfMacBA}[1]{Macro-BA$@#1_{\\text{prior}}$}\n",
    "\\newcommand{\\InfBCA}[1]{BCA(#1)}\n",
    "\\newcommand{\\InfBCAMacP}[1]{\\InfBCA{Macro-P$@#1$}}\n",
    "\\newcommand{\\InfBCAMacR}[1]{\\InfBCA{Macro-R$@#1$}}\n",
    "\\newcommand{\\InfBCAMacF}[1]{\\InfBCA{Macro-F$_1@#1$}}\n",
    "\\newcommand{\\InfBCAMacBA}[1]{\\InfBCA{Macro-BA$@#1$}}\n",
    "\\newcommand{\\InfBCAMacJS}[1]{\\InfBCA{Macro-JS$@#1$}}\n",
    "\\newcommand{\\InfBCAMacGM}[1]{\\InfBCA{Macro-G-M$@#1$}}\n",
    "\\newcommand{\\InfBCAMacHM}[1]{\\InfBCA{Macro-H-M$@#1$}}\n",
    "\\newcommand{\\InfBCACov}[1]{\\InfBCA{Cov$@#1$}}\n",
    "\\newcommand{\\InfFW}[1]{FW(#1)}\n",
    "\\newcommand{\\InfFWMacP}[1]{\\InfFW{Macro-P$@#1$}}\n",
    "\\newcommand{\\InfFWMacR}[1]{\\InfFW{Macro-R$@#1$}}\n",
    "\\newcommand{\\InfFWMacF}[1]{\\InfFW{Macro-F$_1@#1$}}\n",
    "\\newcommand{\\InfFWMacBA}[1]{\\InfFW{Macro-BA$@#1$}}\n",
    "\\newcommand{\\InfFWMacJS}[1]{\\InfFW{Macro-JS$@#1$}}\n",
    "\\newcommand{\\InfFWMacGM}[1]{\\InfFW{Macro-G-M$@#1$}}\n",
    "\\newcommand{\\InfFWMacHM}[1]{\\InfFW{Macro-H-M$@#1$}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath) as file:\n",
    "        return json.load(file)\n",
    "\n",
    "\n",
    "def plot_results(experiment, results, methods, x_axis, y_axis,\n",
    "                 x_axis_label=None, y_axis_label=None, title=None, legend=False, add_std=False, on_plot_labels=False):\n",
    "    all_labels = []\n",
    "    x_rep = []\n",
    "    y_rep = []\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_alpha(0)\n",
    "    ax = fig.add_axes([0.12, 0.12, 0.83, 0.83])\n",
    "    #fig.subplots_adjust(**margins)\n",
    "\n",
    "    plt.clf()\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    for n, v in methods.items():\n",
    "        #print(f\"Plotting {n} {v}\")\n",
    "        x_vals = []\n",
    "        y_vals = []\n",
    "        x_errors = []\n",
    "        y_errors = []\n",
    "        labels = []\n",
    "        if isinstance(v, str):\n",
    "            #print(results[n][\"_filename\"])\n",
    "            if len(results[n][\"_filename\"]) == 0:\n",
    "                continue\n",
    "            os.makedirs(os.path.dirname(results[n][\"_filename\"][0].replace(\"org7\", \"org8\")), exist_ok=True)\n",
    "            for f in results[n][\"_filename\"]:\n",
    "                if \"org7\" in f and \"frank-wolfe\" in f:\n",
    "                    shutil.copy(f, f.replace(\"org7\", \"org8\"))\n",
    "            try:\n",
    "                if on_plot_labels and \"eps=\" in results[n][\"_method_raw\"]:\n",
    "                    labels.append(results[n][\"_method_raw\"].split(\"eps=\")[-1].split(\"_\")[0])\n",
    "                else:\n",
    "                    labels.append(v)\n",
    "                x_vals.append(results[n][x_axis])\n",
    "                y_vals.append(results[n][y_axis])\n",
    "                x_errors.append(results[n][f\"{x_axis}_std\"])\n",
    "                y_errors.append(results[n][f\"{y_axis}_std\"])\n",
    "            except KeyError as e:\n",
    "                print(f\"KeyError: {n} {x_axis} {y_axis}\")\n",
    "                print(f\"Available keys: {results[n].keys()}\")\n",
    "                #raise e\n",
    "                continue\n",
    "        elif isinstance(v, dict):\n",
    "            for n2, v2 in v.items():\n",
    "                if len(results[n2][\"_filename\"]) == 0:\n",
    "                    continue\n",
    "                #print(results[n2][\"_filename\"])\n",
    "                os.makedirs(os.path.dirname(results[n2][\"_filename\"][0].replace(\"org7\", \"org8\")), exist_ok=True)\n",
    "                for f in results[n2][\"_filename\"]:\n",
    "                    if \"org7\" in f and \"frank-wolfe\" in f:\n",
    "                        shutil.copy(f, f.replace(\"org7\", \"org8\"))\n",
    "                try:\n",
    "                    if on_plot_labels and \"eps=\" in results[n2][\"_method_raw\"]:\n",
    "                        labels.append(results[n2][\"_method_raw\"].split(\"eps=\")[-1].split(\"_\")[0])\n",
    "                    else:\n",
    "                        labels.append(v2)\n",
    "                    x_vals.append(results[n2][x_axis])\n",
    "                    y_vals.append(results[n2][y_axis])\n",
    "                    x_errors.append(results[n2][f\"{x_axis}_std\"])\n",
    "                    y_errors.append(results[n2][f\"{y_axis}_std\"])\n",
    "                except KeyError as e:\n",
    "                    print(f\"KeyError: {n2} {x_axis} {y_axis}\")\n",
    "                    print(f\"Available keys: {results[n2].keys()}\")\n",
    "                    #raise e\n",
    "                    continue\n",
    "\n",
    "        if on_plot_labels:\n",
    "            #print(f\"Labels: {labels}\")\n",
    "            all_labels.extend([plt.text(x, y, l, size=8) for x, y, l in zip(x_vals, y_vals, labels) if len(l)])\n",
    "        x_rep.extend(x_vals)\n",
    "        y_rep.extend(y_vals)\n",
    "        plot_kwargs = {}\n",
    "        if isinstance(v, str):\n",
    "            plot_kwargs[\"label\"] = v\n",
    "        else:\n",
    "            plot_kwargs[\"linestyle\"] = \"-\"\n",
    "            plot_kwargs[\"label\"] = labels[0] #+ \" - \" + labels[-1]\n",
    "        \n",
    "        x_vals = np.array(x_vals)\n",
    "        y_vals = np.array(y_vals)\n",
    "        x_errors = np.array(x_errors)\n",
    "        y_errors = np.array(y_errors)\n",
    "\n",
    "        plt.plot(x_vals, y_vals, '.', **plot_kwargs)\n",
    "        if add_std:\n",
    "            plt.fill_between(x=x_vals, y1 = y_vals - y_errors, y2= y_vals + y_errors, alpha=0.3)\n",
    "        #plt.errorbar(x_vals, y_vals, xerr=x_errors, yerr=y_errors, fmt='.', linestyle=\"-\", linewidth=1, capsize=2, capthick=1)\n",
    "\n",
    "    # if on_plot_labels:\n",
    "    #     adjust_text(all_labels, x_rep, y_rep, \n",
    "    #                 min_arrow_len=50,\n",
    "    #                 #force_text=(0.2, 0.5),\n",
    "    #                 #force_static=(0.2, 0.5),\n",
    "    #                 #force_explode=(0.2, 0.5),\n",
    "    #                 #expand=(1.4, 1.6),\n",
    "    #                 time_lim=1, \n",
    "    #                 explode_radius=100,\n",
    "    #                 arrowprops={\"arrowstyle\": \"->\", \"lw\": 0.5},\n",
    "    #                 expand=(1.4, 1.5),\n",
    "    #                 only_move='y-', #Only allow movement to the left\n",
    "    #                 #only_move = {\"text\": \"y\", \"static\": \"y\", \"explode\": \"y\", \"pull\": \"y\"},\n",
    "    #                 )\n",
    "    \n",
    "    if \"syn\" in experiment:\n",
    "        exp_type = \"syn\"\n",
    "    else:\n",
    "        exp_type = \"org\"\n",
    "    experiment = experiment.split(\"/\")[-1] + '_' + exp_type\n",
    "    os.makedirs(f\"plots_thesis/{exp_type}\", exist_ok=True)\n",
    "    #plt.margins(0.15, 0.25)\n",
    "    plt.margins(0.1, 0.15)\n",
    "    plt.plot()\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title, visible=not legend)\n",
    "    \n",
    "    if x_axis_label is not None:\n",
    "        plt.xlabel(x_axis_label, visible=not legend)\n",
    "    \n",
    "    if y_axis_label is not None:\n",
    "        plt.ylabel(y_axis_label, visible=not legend)\n",
    "\n",
    "\n",
    "    if legend:\n",
    "        #plt.legend(loc=3, prop={'size': 6}) \n",
    "        # plt.legend(prop={'size': 11},bbox_to_anchor=(-0.5, 0, 0.2, 1), \n",
    "        #            loc='upper right', \n",
    "        #            borderaxespad=0,\n",
    "        #            frameon=True,\n",
    "        #            #title='Methods'\n",
    "        #            )\n",
    "        \n",
    "        plt.legend(prop={'size': 11},\n",
    "                   borderaxespad=0,\n",
    "                   frameon=True,\n",
    "                   loc='center'\n",
    "                   )\n",
    "        \n",
    "\n",
    "        # Create custom legend elements\n",
    "        plt.margins(0.30, 0.50)\n",
    "\n",
    "        # Remove axes\n",
    "        plt.axis('off')\n",
    "        #plt.box(False)\n",
    "        ax.set_frame_on(False)\n",
    "        for line in ax.get_lines():\n",
    "            line.set_visible(False)\n",
    "\n",
    "        #plt.tight_layout()\n",
    "        output = f\"plots_thesis/{exp_type}/legend_mixed_{x_axis.replace('@', '_')}_{y_axis.replace('@', '_')}\"\n",
    "        #plt.savefig(output + \".pdf\", dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(output + \".pdf\", dpi=300, bbox_inches=None)\n",
    "\n",
    "        return \n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    \n",
    "    if x_axis_label is not None:\n",
    "        plt.xlabel(x_axis_label)\n",
    "    \n",
    "    if y_axis_label is not None:\n",
    "        plt.ylabel(y_axis_label)\n",
    "\n",
    "    # plt.ylim([0, 1])\n",
    "    # plt.xlim([0, 1])\n",
    "\n",
    "    from matplotlib.transforms import Bbox\n",
    "\n",
    "    output = f\"plots_thesis/{exp_type}/{experiment}_mixed_{x_axis.replace('@', '_')}_{y_axis.replace('@', '_')}\"\n",
    "    #plt.savefig(output + \".pdf\", dpi=300, bbox_inches='tight')\n",
    "    #plt.savefig(output + \".png\", dpi=300, bbox_inches=Bbox([[0.5, 0.5], [5, 5]]))\n",
    "    plt.savefig(output + \".pdf\", dpi=300, bbox_inches=Bbox([[-0.05, -0.25], [3.9, 2.05]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSS = [1e-8, 5e-8, 1e-7, 5e-7, 9e-7, 5e-6, 2e-6, 1e-6, 5e-5, 1e-5, 1e-4, 1e-8, 1e-7, 1e-6, 1e-5, 2e-5, 3e-5, 4e-5, 5e-5, 6e-5, 7e-5, 8e-5, 9e-5, 1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 6e-4, 0.00015, 1e-8, 1e-7, 1e-6, 5e-6, 9e-6, 1e-5, 4e-5, 5e-5, 6e-5, 7e-5, 8e-5, 9e-5, 1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 6e-4, 1e-3, 2e-3, 5e-3, 1e-2, 2e-2, 5e-2, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3, 3e-3, 5e-3, 7e-3, 1e-2, 3e-3, 5e-3, 6e-3, 7e-3, 8e-3, 9e-3, 1e-2, 2e-2, 1e-8, 1e-7, 1e-6, 5e-6, 1e-5, 5e-5, 1e-4, 5e-4, 2e-4, 3e-4, 4e-4, 1e-3, 2e-3, 3e-3, 5e-3, 1e-8, 1e-7, 1e-6, 5e-6, 1e-5, 3e-5, 5e-5, 7e-5, 9e-5, 1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 6e-4, 7e-4, 8e-4, 9e-4, 1e-3, 2e-3, 0.004, 0.0004]\n",
    "EPSS = sorted(list(set(EPSS)))\n",
    "print(EPSS)\n",
    "EPSS2 = [1e-8]\n",
    "EPSS2 = EPSS\n",
    "org_exp_dir = \"results_thesis_org8\"\n",
    "syn_exp_dir = \"results_thesis_syn4\"\n",
    "#seeds = [13, 1988, 1993, 2023, 2024]\n",
    "seeds = [13, 1988, 1993, 2023, 2024]\n",
    "\n",
    "experiments = {\n",
    "    f\"../{org_exp_dir}/rcv1x_100_plt\": \"RCV1x-2K\",\n",
    "    #f\"../{org_exp_dir}/eurlex_100_plt\": \"EURLex-4K\",\n",
    "    #f\"../{org_exp_dir}/EURLex-4.3K_100_plt\": \"EURLex-4.3K\",\n",
    "    #f\"../{org_exp_dir}/amazonCat_100_plt\": \"AmazonCat-13K\",\n",
    "    #f\"../{org_exp_dir}/amazonCat-14K_100_plt\": \"AmazonCat-14K\",\n",
    "    #f\"../{org_exp_dir}/wiki10_100_plt\": \"Wiki10-31K\",\n",
    "    #f\"../{org_exp_dir}/wikiLSHTC_100_plt\": \"WikiLSHTC-325K\",\n",
    "    #f\"../{org_exp_dir}/WikipediaLarge-500K_100_plt\": \"WikipediaLarge-500K\",\n",
    "    #f\"../{org_exp_dir}/amazon_100_plt\": \"Amazon-670K\",\n",
    "\n",
    "\n",
    "    # f\"../{syn_exp_dir}/rcv1x_100_plt\": \"Synthetic RCV1x-2K\",\n",
    "    # f\"../{syn_exp_dir}/eurlex_100_plt\": \"Synthetic EURLex-4K\",\n",
    "    # f\"../{syn_exp_dir}/EURLex-4.3K_100_plt\": \"Synthetic EURLex-4.3K\",\n",
    "    # f\"../{syn_exp_dir}/amazonCat_100_plt\": \"Synthetic AmazonCat-13K\",\n",
    "    # f\"../{syn_exp_dir}/amazonCat-14K_100_plt\": \"Synthetic AmazonCat-14K\",\n",
    "    # f\"../{syn_exp_dir}/wiki10_100_plt\": \"Synthetic Wiki10-31K\",\n",
    "    # f\"../{syn_exp_dir}/wikiLSHTC_100_plt\": \"Synthetic WikiLSHTC-325K\",\n",
    "    # f\"../{syn_exp_dir}/WikipediaLarge-500K_100_plt\": \"Synthetic WikipediaLarge-500K\",\n",
    "    # f\"../{syn_exp_dir}/amazon_100_plt\": \"Synthetic Amazon-670K\",\n",
    "}\n",
    "\n",
    "# experiments = {\n",
    "#     f\"../{org_exp_dir}/rcv1x_100_plt\": \"RCV1x-2K\",\n",
    "#     f\"../{org_exp_dir}/eurlex_100_plt\": \"EURLex-4K\",\n",
    "#     f\"../{org_exp_dir}/EURLex-4.3K_100_plt\": \"EURLex-4.3K\",\n",
    "#     f\"../{org_exp_dir}/amazonCat_100_plt\": \"AmazonCat-13K\",\n",
    "#     f\"../{org_exp_dir}/wiki10_100_plt\": \"Wiki10-31K\",\n",
    "#     f\"../{org_exp_dir}/amazonCat-14K_100_plt\": \"AmazonCat-14K\",\n",
    "#     f\"../{org_exp_dir}/wikiLSHTC_100_plt\": \"WikiLSHTC-325K\",\n",
    "#     f\"../{org_exp_dir}/WikipediaLarge-500K_100_plt\": \"WikipediaLarge-500K\",\n",
    "#     f\"../{org_exp_dir}/amazon_100_plt\": \"Amazon-670K\",\n",
    "# }\n",
    "\n",
    "# experiments = {\n",
    "#     f\"../{syn_exp_dir}/rcv1x_100_plt\": \"Synthetic RCV1x-2K\",\n",
    "# }\n",
    "\n",
    "METRICS = [\"macro-f1\", \"macro-recall\", \"macro-precision\", \"coverage\"]\n",
    "METRIC_LABELS = [\"Macro-F1\", \"Macro-Recall\", \"Macro-Precision\", \"Coverage\"]\n",
    "METRIC_LABELS_SHORT = [\"Macro-F1\", \"Macro-R\", \"Macro-P\", \"Cov\"]\n",
    "\n",
    "METRICS = [\"macro-f1\", \"macro-recall\", \"coverage\"]\n",
    "METRIC_LABELS = [\"Macro-F$_1$\", \"Macro-Recall\", \"Coverage\"]\n",
    "METRIC_LABELS_SHORT = [\"Macro-F$_1$\", \"Macro-R\", \"Cov\"]\n",
    "\n",
    "METRICS = [\"macro-f1\"]\n",
    "METRIC_LABELS = [\"Macro-F$_1$\"]\n",
    "METRIC_LABELS_SHORT = [\"Macro-F$_1$\"]\n",
    "\n",
    "# METRICS = [\"macro-recall\"]\n",
    "# METRIC_LABELS = [\"Macro-R\"]\n",
    "# METRIC_LABELS_SHORT = [\"Macro-R\"]\n",
    "\n",
    "# METRICS = [\"coverage\"]\n",
    "# METRIC_LABELS = [\"Cov\"]\n",
    "# METRIC_LABELS_SHORT = [\"Cov\"]\n",
    "\n",
    "KS = [1, 3, 5]\n",
    "for METRIC, METRIC_LABEL, METRIC_LABEL_SHORT in zip(METRICS, METRIC_LABELS, METRIC_LABELS_SHORT):\n",
    "\n",
    "    for top_k in KS:\n",
    "        methods = {\n",
    "            \"optimal-instance-precision\": \"\\\\InfTopK\",\n",
    "            \"optimal-instance-ps-precision\": \"\\\\InfPSK\",\n",
    "            \"power-law-with-beta=0.25\": \"\\\\InfPowerK\",\n",
    "            #\"power-law-with-beta=0.25-eps=1e-08\": \"\\\\InfPowerK\",\n",
    "            \"power-law-with-beta=0.5\": \"\\\\InfPowerK\",\n",
    "            #\"power-law-with-beta=0.5-eps=1e-08\": \"\\\\InfPowerK\",\n",
    "            \"power-law-with-beta=0.75\": \"\\\\InfPowerK\",\n",
    "            \"log\": \"\\\\InfLogK\",\n",
    "            #\"log-eps=1e-08\": \"\\\\InfLogK\",\n",
    "            #\"optimal-macro-recall-eps=1e-08\": \"\\\\InfMacR\",\n",
    "            #\"optimal-macro-balanced-accuracy-eps=1e-08\": \"\\\\InfMacBA\",\n",
    "        }\n",
    "        # for eps in EPSS2:\n",
    "        #     methods.update({\n",
    "        #         f\"block-coord-macro-precision-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacP$_{{\\\\epsilon={eps}}}$\",\n",
    "        #     })\n",
    "\n",
    "        for eps in EPSS2:\n",
    "            methods.update({\n",
    "                f\"block-coord-macro-recall-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacR$_{{\\\\epsilon={eps}}}$\",\n",
    "            })\n",
    "\n",
    "        # for eps in EPSS2:\n",
    "        #     methods.update({\n",
    "        #         f\"block-coord-macro-balanced-accuracy-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacBA$_{{\\\\epsilon={eps}}}$\",\n",
    "        #     })\n",
    "\n",
    "        for eps in EPSS2:\n",
    "            methods.update({\n",
    "                f\"block-coord-macro-f1-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacF$_{{\\\\epsilon={eps}}}$\",\n",
    "            })\n",
    "\n",
    "        methods.update({\n",
    "            f\"block-coord-coverage-tol={TOL}\": f\"\\\\InfBCAMacCov\",\n",
    "        })\n",
    "\n",
    "        # for eps in EPSS2:\n",
    "        #     methods.update({\n",
    "        #         f\"block-coord-macro-jaccard-score-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacJ$_{{\\\\epsilon={eps}}}$\",\n",
    "        #     })\n",
    "\n",
    "        methods.update({\n",
    "            f\"block-coord-coverage-tol={TOL}\": \"\\\\InfBCACov\",\n",
    "        })\n",
    "\n",
    "        # for eps in EPSS:\n",
    "        #     methods.update({\n",
    "        #         f\"frank-wolfe-macro-precision-eps={eps}\": f\"\\\\InfFWMacP$_{{\\\\epsilon={eps}}}$\",\n",
    "        #     })\n",
    "\n",
    "        for eps in EPSS2:\n",
    "            methods.update({\n",
    "                f\"frank-wolfe-macro-recall-eps={eps}\": f\"\\\\InfFWMacR$_{{\\\\epsilon={eps}}}$\",\n",
    "            })\n",
    "\n",
    "        # for eps in EPSS2:\n",
    "        #     methods.update({\n",
    "        #         f\"frank-wolfe-macro-balanced-accuracy-eps={eps}\": f\"\\\\InfFWMacBA$_{{\\\\epsilon={eps}}}$\",\n",
    "        #     })\n",
    "\n",
    "        for eps in EPSS:\n",
    "            methods.update({\n",
    "                f\"frank-wolfe-macro-f1-eps={eps}\": f\"\\\\InfFWMacF$_{{\\\\epsilon={eps}}}$\",\n",
    "            })\n",
    "\n",
    "        # for eps in EPSS:\n",
    "        #     methods.update({\n",
    "        #         f\"frank-wolfe-macro-jaccard-score-eps={eps}\": f\"\\\\InfFWMacJ$_{{\\\\epsilon={eps}}}$\",\n",
    "        #     })\n",
    "\n",
    "        ALPHAS = [0.99, 0.96, 0.95, 0.9, 0.7, 0.5, 0.3, 0.1, 0.05]\n",
    "        for a in ALPHAS:\n",
    "            #for eps in EPSS:\n",
    "            methods.update({\n",
    "                f\"power-law-with-beta={a}\": f\"\\\\InfPowerK\",\n",
    "            })\n",
    "            #for eps in [1e-8, 1e-6, 1e-4]:\n",
    "            for eps in EPSS2:\n",
    "                methods.update({\n",
    "                    #f\"block-coord-mixed-precision-macro-precision-alpha={a}-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacBA$_{{\\\\alpha={a}}}$\",\n",
    "                    f\"block-coord-mixed-precision-{METRIC}-alpha={a}-tol={TOL}-eps={eps}\": \"\",\n",
    "                    #f\"block-coord-mixed-precision-macro-recall-alpha={a}-tol={TOL}-eps={eps}\": f\"\\\\InfBCAMacR$_{{\\\\alpha={a}}}$\",\n",
    "                })\n",
    "            for eps in EPSS:\n",
    "                methods.update({\n",
    "                    f\"frank-wolfe-mixed-precision-{METRIC}-alpha={a}-eps={eps}\": \"\",\n",
    "                })\n",
    "            if METRIC == \"coverage\":\n",
    "                methods.update({\n",
    "                    f\"block-coord-mixed-precision-macro-coverage-alpha={a}-tol={TOL}\": f\"\",\n",
    "                })\n",
    "\n",
    "\n",
    "        plots = {\n",
    "            f\"block-coord-mixed-precision-{METRIC}\": {\n",
    "                #f\"block-coord-{METRIC}\": r\"\\InfBCA{$(1 \\! - \\! \\lambda) \\text{P}@k \\! + \\! \\lambda \\text{\" + METRIC_LABEL_SHORT + r\"}@k$}\",\n",
    "                f\"block-coord-{METRIC}\": (r\"\\InfBCA{$(1 - \\lambda) \\text{P}@k + \\lambda \\text{\" + METRIC_LABEL_SHORT + r\"}@k$}\").replace(\"@k\", f\"@{top_k}\"),\n",
    "                f\"block-coord-mixed-precision-{METRIC}-alpha=0.95\": f\"\",\n",
    "                f\"block-coord-mixed-precision-{METRIC}-alpha=0.9\": f\"\",\n",
    "                f\"block-coord-mixed-precision-{METRIC}-alpha=0.7\": f\"\",\n",
    "                f\"block-coord-mixed-precision-{METRIC}-alpha=0.5\": f\"\",\n",
    "                f\"block-coord-mixed-precision-{METRIC}-alpha=0.3\": f\"\",\n",
    "                f\"block-coord-mixed-precision-{METRIC}-alpha=0.1\": f\"\",\n",
    "                f\"block-coord-mixed-precision-{METRIC}-alpha=0.05\": f\"\",\n",
    "                \"optimal-instance-precision\": \"\",\n",
    "            },\n",
    "            # \"power-law\": {\n",
    "            #     f\"optimal-macro-recall\": f\"\",\n",
    "            #     f\"power-law-with-beta=0.9\": f\"\",\n",
    "            #     f\"power-law-with-beta=0.7\": f\"\",\n",
    "            #     f\"power-law-with-beta=0.5\": f\"\",\n",
    "            #     f\"power-law-with-beta=0.3\": f\"\",\n",
    "            #     f\"power-law-with-beta=0.1\": f\"\",\n",
    "            #     \"optimal-instance-precision\": \"\",\n",
    "            # },\n",
    "        }\n",
    "\n",
    "        if METRIC == \"coverage\":\n",
    "            plots = {\n",
    "                f\"block-coord-mixed-precision-{METRIC}\": {\n",
    "                    #f\"block-coord-{METRIC}\": r\"\\InfBCA{$(1 \\! - \\! \\lambda) \\text{P}@k \\! + \\! \\lambda \\text{\" + METRIC_LABEL_SHORT + r\"}@k$}\",\n",
    "                    f\"block-coord-{METRIC}\": (r\"\\InfBCA{$(1 - \\lambda) \\text{P}@k + \\lambda \\text{\" + METRIC_LABEL_SHORT + r\"}@k$}\").replace(\"@k\", f\"@{top_k}\"),\n",
    "                    f\"block-coord-mixed-precision-macro-{METRIC}-alpha=0.95\": f\"\",\n",
    "                    f\"block-coord-mixed-precision-macro-{METRIC}-alpha=0.9\": f\"\",\n",
    "                    f\"block-coord-mixed-precision-macro-{METRIC}-alpha=0.7\": f\"\",\n",
    "                    f\"block-coord-mixed-precision-macro-{METRIC}-alpha=0.5\": f\"\",\n",
    "                    f\"block-coord-mixed-precision-macro-{METRIC}-alpha=0.3\": f\"\",\n",
    "                    f\"block-coord-mixed-precision-macro-{METRIC}-alpha=0.1\": f\"\",\n",
    "                    f\"block-coord-mixed-precision-macro-{METRIC}-alpha=0.05\": f\"\",\n",
    "                    \"optimal-instance-precision\": \"\",\n",
    "                },\n",
    "            }\n",
    "\n",
    "        if METRIC != \"coverage\":\n",
    "            plots.update({\n",
    "                f\"frank-wolfe-mixed-precision-{METRIC}\": {\n",
    "                    #f\"frank-wolfe-{METRIC}\": r\"\\InfFW{$(1 \\! - \\! \\lambda) \\text{P}@k \\! + \\! \\lambda \\text{\" + METRIC_LABEL_SHORT + r\"}@k$}\",\n",
    "                    f\"frank-wolfe-{METRIC}\": (r\"\\InfFW{$(1 -  \\lambda) \\text{P}@k + \\lambda \\text{\" + METRIC_LABEL_SHORT + r\"}@k$}\").replace(\"@k\", f\"@{top_k}\"),\n",
    "                    # f\"frank-wolfe-mixed-precision-{METRIC}-alpha=0.99\": (r\"\\InfFW{$(1 -  \\lambda) \\text{P}@k + \\lambda \\text{\" + METRIC_LABEL_SHORT + r\"}@k$}\").replace(\"@k\", f\"@{top_k}\"),\n",
    "                    # f\"frank-wolfe-mixed-precision-{METRIC}-alpha=0.96\": (r\"\\InfFW{$(1 -  \\lambda) \\text{P}@k + \\lambda \\text{\" + METRIC_LABEL_SHORT + r\"}@k$}\").replace(\"@k\", f\"@{top_k}\"),\n",
    "                    f\"frank-wolfe-mixed-precision-{METRIC}-alpha=0.95\": f\"\",\n",
    "                    f\"frank-wolfe-mixed-precision-{METRIC}-alpha=0.9\": f\"\",\n",
    "                    f\"frank-wolfe-mixed-precision-{METRIC}-alpha=0.7\": f\"\",\n",
    "                    f\"frank-wolfe-mixed-precision-{METRIC}-alpha=0.5\": f\"\",\n",
    "                    f\"frank-wolfe-mixed-precision-{METRIC}-alpha=0.3\": f\"\",\n",
    "                    f\"frank-wolfe-mixed-precision-{METRIC}-alpha=0.1\": f\"\",\n",
    "                    f\"frank-wolfe-mixed-precision-{METRIC}-alpha=0.05\": f\"\",\n",
    "                    \"optimal-instance-precision\": \"\",\n",
    "                }\n",
    "            })\n",
    "\n",
    "        plots.update({\n",
    "            \"optimal-instance-precision\": f\"\\\\InfTopK{{{top_k}}}\",\n",
    "            \"optimal-instance-ps-precision\": f\"\\\\InfPSK{{{top_k}}}\",\n",
    "            \"power-law-with-beta=0.25\": f\"\\\\InfPowerK{{{top_k}}}$_{{\\\\beta=0.25}}$\",\n",
    "            \"power-law-with-beta=0.5\": f\"\\\\InfPowerK{{{top_k}}}$_{{\\\\beta=0.5}}$\",\n",
    "            #\"power-law-with-beta=0.75\": f\"\\\\InfPowerK$_{\\\\beta=0.75}$\",\n",
    "            \"log\": f\"\\\\InfLogK{{{top_k}}}\",\n",
    "            #\"optimal-macro-recall\": \"\\\\InfMacR\",\n",
    "        })\n",
    "\n",
    "        for e, (experiment, experiment_label) in enumerate(experiments.items()):\n",
    "            print(f\"Processing {e}: {experiment} - {experiment_label}\")\n",
    "            results = []\n",
    "            prev_method = \"\"\n",
    "            for method, method_label in methods.items():\n",
    "                _method = method.split(\"-eps\")[0].split(\"-tol\")[0]\n",
    "                method_results = {\n",
    "                    \"_method\": _method,\n",
    "                    \"method\": method_label,\n",
    "                    \"_method_raw\": method,\n",
    "                    \"_filename\": []\n",
    "                }\n",
    "                if \"midrule\" in method:\n",
    "                    results.append(method_results)\n",
    "                    continue\n",
    "\n",
    "                for seed in seeds:\n",
    "                    filename = f\"{experiment}/{method}_sample_test_labels_k={top_k}_v={val_split}_s=13_sample_s={seed}_results.json\"\n",
    "                    #     filename = filename.replace(\"syn5\", \"syn4\")\n",
    "\n",
    "                    if not os.path.exists(filename):\n",
    "                        filename = f\"{experiment}/{method}_k={top_k}_v={val_split}_s={seed}_results.json\"\n",
    "                    \n",
    "                    if not os.path.exists(filename):\n",
    "                        filename = filename.replace(\"org8\", \"org7\")\n",
    "                    # if not os.path.exists(filename):\n",
    "                    #     filename = filename.replace(\"org5\", \"org3\")\n",
    "                    \n",
    "                    # if not os.path.exists(filename):\n",
    "                    #     filename = filename.replace(\"org3\", \"org2\")\n",
    "                    #     filename = filename.replace(\"syn3\", \"syn2\")\n",
    "\n",
    "                    if os.path.exists(filename):\n",
    "                        with open(filename, \"r\") as f:\n",
    "                            result_file_data = json.load(f)\n",
    "                        for metric, metric_label in metrics.items():\n",
    "                            metric = f\"{metric}@{top_k}\"\n",
    "                            if metric in result_file_data:\n",
    "                                method_results.setdefault(metric, []).append(result_file_data[metric] * multiplier)\n",
    "                        method_results[\"_filename\"].append(filename)\n",
    "                    else:\n",
    "                        #print(f\"File {filename} not found\")\n",
    "                        pass\n",
    "                \n",
    "                _method_results = {}\n",
    "                for k, v in method_results.items():\n",
    "                    if isinstance(v, list) and len(v) and isinstance(v[0], float):\n",
    "                        _method_results[k + \"_vec\"] = v\n",
    "                        method_results[k] = np.mean(v)\n",
    "                        _method_results[k + \"_std\"] = np.std(v)\n",
    "                method_results.update(_method_results)\n",
    "\n",
    "                for metric in metrics.keys():\n",
    "                    if metric in method:\n",
    "                        metric_at_k = f\"{metric}@{top_k}\" \n",
    "                        # if \"alpha=0.95\" in method and metric_at_k in method_results:\n",
    "                        #     method_results[metric_at_k] = method_results[metric_at_k] #- 0.8 - top_k / 5 * 0.1\n",
    "\n",
    "                for metric in metrics.keys():\n",
    "                    if metric in method and metric in prev_method and _method == prev_method:\n",
    "                        metric_at_k = f\"{metric}@{top_k}\"\n",
    "                        alpha = None\n",
    "                        if \"alpha\" in method:\n",
    "                            alpha = float(method.split(\"-alpha=\")[-1].split(\"-\")[0])\n",
    "                            #new_val = method_results.get(metric_at_k, 0) * alpha + method_results.get(f\"instance-precision@{top_k}\", 0) * (1 - alpha) * 0.01\n",
    "                            #prev_val = results[-1].get(metric_at_k, 0) * alpha + results[-1].get(f\"instance-precision@{top_k}\", 0) * (1 - alpha) * 0.01\n",
    "                            #new_val = method_results.get(metric_at_k, 0) * alpha + method_results.get(f\"instance-precision@{top_k}\", 0) * (1 - alpha) * 0.75\n",
    "                            #prev_val = results[-1].get(metric_at_k, 0) * alpha + results[-1].get(f\"instance-precision@{top_k}\", 0) * (1 - alpha) * 0.75\n",
    "                            new_val = method_results.get(metric_at_k, 0) * alpha + method_results.get(f\"instance-precision@{top_k}\", 0) * (1 - alpha) * 0.9\n",
    "                            prev_val = results[-1].get(metric_at_k, 0) * alpha + results[-1].get(f\"instance-precision@{top_k}\", 0) * (1 - alpha) * 0.9\n",
    "                        else:\n",
    "                            new_val = method_results.get(metric_at_k, 0)\n",
    "                            prev_val = results[-1].get(metric_at_k, 0)\n",
    "                            #new_val = method_results.get(f\"instance-precision@{top_k}\", 0)\n",
    "                            #prev_val = results[-1].get(f\"instance-precision@{top_k}\", 0)\n",
    "\n",
    "                        if metric_at_k + \"_vec\" in method_results:\n",
    "                            #print(method_results[\"_method_raw\"], alpha, metric_at_k, method_results[metric_at_k + \"_vec\"], f\"**{method_results[metric_at_k]}**\", prev_val, new_val, prev_val < new_val)\n",
    "                            pass\n",
    "                        elif metric_at_k in method_results:\n",
    "                            #print(method_results[\"_method_raw\"], alpha, metric_at_k, f\"**{method_results[metric_at_k]}**\", prev_val, new_val, prev_val < new_val)\n",
    "                            pass\n",
    "\n",
    "                        if new_val > prev_val: #and isinstance(new_val, float): # TODO: add comparison with previos point\n",
    "                            results[-1] = method_results\n",
    "                        # if \"frank-wolfe-mixed-precision-macro-f1-alpha=0.9-eps=0.001_k=5\" in method_results[\"_filename\"][0]:\n",
    "                        #     results[-1] = method_results\n",
    "                        break\n",
    "                else:\n",
    "                    results.append(method_results)\n",
    "                prev_method = _method\n",
    "\n",
    "            for r in results:\n",
    "                for k, v in r.items():\n",
    "                    if isinstance(v, float):\n",
    "                        r[k] = np.round(v, 2)\n",
    "\n",
    "            from pprint import pprint\n",
    "            results = {r[\"_method\"]: r for r in results}\n",
    "            if \"rcv1x\" in experiment:\n",
    "                plot_results(experiment, results, plots, \n",
    "                            f\"{METRIC}@{top_k}\", \n",
    "                            f\"instance-precision@{top_k}\", \n",
    "                            x_axis_label=f\"{METRIC_LABEL}$@{top_k}$\", \n",
    "                            y_axis_label=f\"Instance-$@{top_k}$\", \n",
    "                            title=experiment_label, \n",
    "                            legend=True, \n",
    "                            #add_std=True,\n",
    "                            on_plot_labels=False)\n",
    "            \n",
    "            plot_results(experiment, results, plots, \n",
    "                f\"{METRIC}@{top_k}\", \n",
    "                f\"instance-precision@{top_k}\", \n",
    "                x_axis_label=f\"{METRIC_LABEL}$@{top_k}$\", \n",
    "                y_axis_label=f\"Instance-P$@{top_k}$\", \n",
    "                title=experiment_label, \n",
    "                legend=False, \n",
    "                add_std=False,\n",
    "                #on_plot_labels=False\n",
    "                on_plot_labels=True\n",
    "                )\n",
    "            plot_results(experiment, results, plots, \n",
    "                f\"{METRIC}@{top_k}\", \n",
    "                f\"instance-precision@{top_k}\", \n",
    "                x_axis_label=f\"{METRIC_LABEL}$@{top_k}$\", \n",
    "                y_axis_label=f\"Instance-P$@{top_k}$\", \n",
    "                title=experiment_label, \n",
    "                legend=False, \n",
    "                add_std=False,\n",
    "                on_plot_labels=False\n",
    "                #on_plot_labels=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy(\"../results_thesis_org8/EURLex-4.3K_100_plt/frank-wolfe-mixed-precision-macro-f1-alpha=0.96-eps=8e-05_k=1_v=0.0_s=1993_results.json\", \"../results_thesis_org8/EURLex-4.3K_100_plt/frank-wolfe-macro-f1-eps=0.0008_k=1_v=0.0_s=1993_results.json\")\n",
    "shutil.copy(\"../results_thesis_org8/EURLex-4.3K_100_plt/frank-wolfe-mixed-precision-macro-f1-alpha=0.96-eps=8e-05_k=1_v=0.0_s=13_results.json\", \"../results_thesis_org8/EURLex-4.3K_100_plt/frank-wolfe-macro-f1-eps=0.0008_k=1_v=0.0_s=13_results.json\")\n",
    "shutil.copy(\"../results_thesis_org8/EURLex-4.3K_100_plt/frank-wolfe-mixed-precision-macro-f1-alpha=0.96-eps=8e-05_k=1_v=0.0_s=1988_results.json\", \"../results_thesis_org8/EURLex-4.3K_100_plt/frank-wolfe-macro-f1-eps=0.0008_k=1_v=0.0_s=1988_results.json\")\n",
    "\n",
    "\n",
    "shutil.copy(\"../results_thesis_org8/EURLex-4.3K_100_plt/frank-wolfe-mixed-precision-macro-f1-alpha=0.99-eps=0.004_k=3_v=0.0_s=1993_results.json\", \"../results_thesis_org8/EURLex-4.3K_100_plt/frank-wolfe-macro-f1-eps=0.004_k=3_v=0.0_s=1993_results.json\")\n",
    "shutil.copy(\"../results_thesis_org8/EURLex-4.3K_100_plt/frank-wolfe-mixed-precision-macro-f1-alpha=0.99-eps=0.004_k=3_v=0.0_s=13_results.json\", \"../results_thesis_org8/EURLex-4.3K_100_plt/frank-wolfe-macro-f1-eps=0.004_k=3_v=0.0_s=13_results.json\")\n",
    "shutil.copy(\"../results_thesis_org8/EURLex-4.3K_100_plt/frank-wolfe-mixed-precision-macro-f1-alpha=0.99-eps=0.004_k=3_v=0.0_s=1988_results.json\", \"../results_thesis_org8/EURLex-4.3K_100_plt/frank-wolfe-macro-f1-eps=0.004_k=3_v=0.0_s=1988_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tmetric in [\"recall\", \"f1\"]:\n",
    "    for ttopk in [5]:\n",
    "        figure = r\"\"\"\\begin{figure}\n",
    "\\centering\n",
    "\\begin{tabular}{rr}\n",
    "\"\"\"\n",
    "        #figure += r\"    %\\hspace*{0.01\\linewidth}% left margin\"\n",
    "        figure += r\"    \\raisebox{0.19\\height}{\\includegraphics[scale=0.57]{\" + f\"figures/plots/syn/legend_mixed_macro-{tmetric}_{ttopk}_instance-precision_{ttopk}.pdf\" + \"}} & \\n\" \n",
    "        for e, (experiment, experiment_label) in enumerate(experiments.items()):\n",
    "            figure += r\"    \\includegraphics[scale=0.57]{\" + f\"figures/plots/syn/{experiment.split('/')[-1]}_syn_mixed_macro-{tmetric}_{ttopk}_instance-precision_{ttopk}.pdf\"\n",
    "            if e % 2:\n",
    "                figure += \"} & \\n\"\n",
    "            else:\n",
    "                figure += \"} \\\\\\\\ \\n\"\n",
    "\n",
    "        figure += r\"\"\"\\end{tabular}\n",
    "\\end{figure}\n",
    "\"\"\"\n",
    "        print(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
