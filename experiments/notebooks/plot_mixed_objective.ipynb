{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot mixed objectives\n",
    "\n",
    "This notebook generates the plots of the mixed objectives that are used in the papers:\n",
    "\n",
    "Erik Schultheis, Marek Wydmuch, Wojciech Kotłowski, Rohit Babbar, Krzysztof Dembczyński. _Generalized test utilities for long-tail performance in extreme multi-label classification_. NeurIPS 2023.\n",
    "\n",
    "Erik Schultheis, Wojciech Kotłowski, Marek Wydmuch, Rohit Babbar, Strom Borman, Krzysztof Dembczyński. _Consistent algorithms for multi-label classification with macro-at-k metrics_. ICLR 2024.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Function for creating the plots\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "from collections.abc import Iterable\n",
    "import os\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (4, 2), # for smaller plots\n",
    "    #\"figure.figsize\": (4, 2.5), # ICLR paper\n",
    "    #\"figure.figsize\": (4, 3), # NeurIPS paper\n",
    "    \"figure.dpi\": 300,\n",
    "    \"figure.autolayout\": False,\n",
    "    \"text.usetex\": True,\n",
    "    'mathtext.fontset': 'stix',\n",
    "    'font.family': 'STIXGeneral',\n",
    "    'savefig.transparent': False,\n",
    "})\n",
    "\n",
    "plt.rcParams[\"text.latex.preamble\"]= \"\\n\".join([\"\\\\usepackage[T1]{fontenc}\", \"\\\\usepackage{bold-extra}\"])#, \"\\\\usepackage{lmodern}\"]\n",
    "\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath) as file:\n",
    "        return json.load(file)\n",
    "\n",
    "\n",
    "def plot_results(experiment, methods, x_axis, y_axis, k, seeds, \n",
    "                 x_axis_label=None, y_axis_label=None, title=None, legend=False):\n",
    "    texts = []\n",
    "    x_rep = []\n",
    "    y_rep = []\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_alpha(0)\n",
    "\n",
    "    plt.clf()\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    for n, v in methods.items():\n",
    "        x_vals = []\n",
    "        y_vals = []\n",
    "        x_errors = []\n",
    "        y_errors = []\n",
    "        for m, l in v.items():\n",
    "            y = []\n",
    "            x = []\n",
    "            x_error = 0\n",
    "            y_error = 0\n",
    "\n",
    "            if isinstance(seeds, Iterable):\n",
    "                for seed in seeds:\n",
    "                    path1 = f\"{experiment}{m.format(k, seed)}_results.json\"\n",
    "                    path2 = f\"{experiment}{m}_k={k}_s={seed}_results.json\"\n",
    "                    if os.path.exists(path1):\n",
    "                        path = path1\n",
    "                    elif os.path.exists(path2):\n",
    "                        path = path2\n",
    "                    else:\n",
    "                        print(f\"Missing: {path1} / {path2}\")\n",
    "                        return\n",
    "\n",
    "                    method = load_json(path)\n",
    "                    x.append(method[x_axis])\n",
    "                    y.append(method[y_axis])\n",
    "\n",
    "            if isinstance(x, list):\n",
    "                x = np.array(x) * 100\n",
    "                x_error = np.std(x)\n",
    "                x = np.mean(x)\n",
    "            \n",
    "            if isinstance(y, list):\n",
    "                y = np.array(y) * 100\n",
    "                y_error = np.std(y)\n",
    "                y = np.mean(y)\n",
    "\n",
    "            x_vals.append(x)\n",
    "            y_vals.append(y)\n",
    "            x_errors.append(x_error)\n",
    "            y_errors.append(y_error)\n",
    "            \n",
    "            if l is not None:\n",
    "                texts.append(plt.text(x_vals[-1], y_vals[-1], l, size=8))\n",
    "                x_rep.append(x_vals[-1])\n",
    "                y_rep.append(y_vals[-1])\n",
    "        x_vals = np.array(x_vals)\n",
    "        y_vals = np.array(y_vals)\n",
    "        x_errors = np.array(x_errors)\n",
    "        y_errors = np.array(y_errors)\n",
    "        plt.plot(x_vals, y_vals, '.', linestyle=\"-\")\n",
    "        #plt.fill_between(x=x_vals, y1 = y_vals - y_errors, y2= y_vals + y_errors, alpha=0.3)\n",
    "        #plt.errorbar(x_vals, y_vals, xerr=x_errors, yerr=y_errors, fmt='.', linestyle=\"-\", linewidth=1, capsize=2, capthick=1)\n",
    "\n",
    "    adjust_text(texts, x_rep, y_rep, \n",
    "                min_arrow_len=50,\n",
    "                #force_text=(0.2, 0.5),\n",
    "                #force_static=(0.2, 0.5),\n",
    "                #force_explode=(0.2, 0.5),\n",
    "                #expand=(1.4, 1.6),\n",
    "                time_lim=1, \n",
    "                explode_radius=100,\n",
    "                arrowprops={\"arrowstyle\": \"->\", \"lw\": 0.5},\n",
    "                expand=(1.4, 1.5),\n",
    "                only_move='y-', #Only allow movement to the left\n",
    "                #only_move = {\"text\": \"y\", \"static\": \"y\", \"explode\": \"y\", \"pull\": \"y\"},\n",
    "                )\n",
    "    \n",
    "    if legend:\n",
    "        plt.legend()\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    \n",
    "    if x_axis_label is not None:\n",
    "        plt.xlabel(x_axis_label)\n",
    "    \n",
    "    if y_axis_label is not None:\n",
    "        plt.ylabel(y_axis_label)\n",
    "\n",
    "    # plt.ylim([0, 1])\n",
    "    # plt.xlim([0, 1])\n",
    "    plt.margins(0.15, 0.25)\n",
    "    plt.plot()\n",
    "    ourput = f\"plots/{experiment.split('/')[-1]}_mixed_{x_axis.replace('@', '_')}_{y_axis.replace('@', '_')}\"\n",
    "    plt.savefig(ourput + \".pdf\", dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots for Generalized test utilities for long-tail performance in extreme multi-label classification (NeurIPS 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Plot the results for all the datasets and objectives (p@k mixed with macro-f1@k, macro-prec@k, and macro-cov@k)\n",
    "\n",
    "dataset_names = {\n",
    "    \"eurlex\": \"Eurlex-4K\",\n",
    "    \"amazoncat\": \"AmazonCat-13K\",\n",
    "    \"wiki10\": \"Wiki10-31K\",\n",
    "    \"amazon_1000\": \"Amazon-670K\",\n",
    "    \"wiki500_1000\": \"Wikipedia-500K\",\n",
    "}\n",
    "\n",
    "seeds = [13, 26, 42, 1993, 2023]\n",
    "directory = \"../results/bca_neurips_fixed_mixed\"\n",
    "tol=\"1e-6\"\n",
    "\n",
    "for macro_type in [\"f1\", \"prec\"]:#, \"cov\"]:\n",
    "    for k in [3, 5]:\n",
    "        x_axis = f\"m{macro_type[0].upper()}@{k}\"\n",
    "        y_axis = f\"iP@{k}\"\n",
    "        macro_type_label = macro_type[0].upper()\n",
    "        if macro_type == \"f1\":\n",
    "            macro_type_label = macro_type.upper()\n",
    "        if macro_type == \"cov\":\n",
    "            x_axis_label = f\"Coverage@{k}\"\n",
    "        else:\n",
    "            x_axis_label = f\"Macro-{macro_type_label}@{k}\"\n",
    "        y_axis_label = f\"Instance-P@{k}\"\n",
    "\n",
    "        if macro_type == \"cov\":\n",
    "            methods = {\n",
    "                \"ps-k\": {\"_lightxml/optimal-instance-ps-prec\": \"PS-K\"},\n",
    "                \"log\": {\"_lightxml/log\": \"Log-K\"},\n",
    "                f\"mixed-tol={tol}\": {\n",
    "                    f\"_lightxml/block-coord-{macro_type}-tol={tol}\": f\"Cov\" + \"$_{\\\\mathrm{BCA}}$\",\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.999-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.995-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.99-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.95-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.9-tol={tol}\": \"$\\\\alpha=0.9$\",\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.8-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.7-tol={tol}\": \"$\\\\alpha=0.7$\",\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.6-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.5-tol={tol}\": \"$\\\\alpha=0.5$\",\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.4-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.3-tol={tol}\": \"$\\\\alpha=0.3$\",\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.2-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.1-tol={tol}\": \"$\\\\alpha=0.1$\",\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.05-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.01-tol={tol}\": None,\n",
    "                    f\"_lightxml/optimal-instance-prec\": \"Top-K\",\n",
    "                },\n",
    "                \"pow-beta=0.25\": {\"_lightxml/power-law-with-beta=0.25\": \"Pow-K$_{\\\\beta=0.25}$\"},\n",
    "                \"pow-beta=0.5\": {\"_lightxml/power-law-with-beta=0.5\": \"Pow-K$_{\\\\beta=0.5}$\"},\n",
    "            }\n",
    "        else:\n",
    "            methods = {\n",
    "                \"ps-k\": {\"_lightxml/optimal-instance-ps-prec\": \"PS-K\"},\n",
    "                \"log\": {\"_lightxml/log\": \"Log-K\"},\n",
    "                f\"mixed-tol={tol}\": {\n",
    "                    f\"_lightxml/block-coord-macro-{macro_type}-tol={tol}\": f\"Macro-{macro_type_label}\" + \"$_{\\\\mathrm{BCA}}$\",\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.999-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.995-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.99-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.95-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.9-tol={tol}\": \"$\\\\alpha=0.9$\",\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.8-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.7-tol={tol}\": \"$\\\\alpha=0.7$\",\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.6-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.5-tol={tol}\": \"$\\\\alpha=0.5$\",\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.4-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.3-tol={tol}\": \"$\\\\alpha=0.3$\",\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.2-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.1-tol={tol}\": \"$\\\\alpha=0.1$\",\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.05-tol={tol}\": None,\n",
    "                    f\"_lightxml/block-coord-mixed-prec-{macro_type}-alpha=0.01-tol={tol}\": None,\n",
    "                    f\"_lightxml/optimal-instance-prec\": \"Top-K\",\n",
    "                },\n",
    "                \"pow-beta=0.25\": {\"_lightxml/power-law-with-beta=0.25\": \"Pow-K$_{\\\\beta=0.25}$\"},\n",
    "                \"pow-beta=0.5\": {\"_lightxml/power-law-with-beta=0.5\": \"Pow-K$_{\\\\beta=0.5}$\"},\n",
    "            }\n",
    "\n",
    "        for dataset, title in dataset_names.items():            \n",
    "            plot_results(f\"{directory}/{dataset}\", methods, x_axis, y_axis, k, seeds, x_axis_label, y_axis_label, title)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots for Consistent algorithms for multi-label classification with macro-at-k metrics (ICLR 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dataset_names = {\n",
    "    \"mediamill\": \"\\\\textsc{\\\\textbf{Mediamill}}\",\n",
    "    \"flicker_deepwalk\": \"\\\\textsc{\\\\textbf{Flickr}}\",\n",
    "    \"rcv1x\": \"\\\\textsc{\\\\textbf{RCV1X}}\",\n",
    "    \"amazoncat\": \"\\\\textsc{\\\\textbf{AmazonCat}}\",\n",
    "}\n",
    "\n",
    "seeds = [21, 42, 63] # 147, 168, 189, 210, 231, 252]\n",
    "directory = \"../results/fw_iclr_camera_ready\"\n",
    "step=\"0.001\"\n",
    "\n",
    "for macro_type in [\"f1\"]:#, \"cov\"]:\n",
    "    for k in [3, 5, 10]:\n",
    "        x_axis = f\"m{macro_type[0].upper()}@{k}\"\n",
    "        y_axis = f\"iP@{k}\"\n",
    "        macro_type_label = macro_type[0].upper()\n",
    "        if macro_type == \"f1\":\n",
    "            macro_type_label = macro_type.upper()\n",
    "        x_axis_label = f\"Macro-{macro_type_label}@{k}\"\n",
    "        y_axis_label = f\"Instance-Prec@{k}\"\n",
    "\n",
    "        methods = {\n",
    "            \"pow-beta=0.25\": {f\"_pytorch_bce/fw-split-power-law-with-beta=0.25_k={{}}_s={{}}_t=0.0_r=0.0\": \"Pow-K$_{\\\\beta=0.25}$\"},\n",
    "            \"pow-beta=0.5\": {f\"_pytorch_bce/fw-split-power-law-with-beta=0.5_k={{}}_s={{}}_t=0.0_r=0.0\": \"Pow-K$_{\\\\beta=0.5}$\"},\n",
    "            f\"mixed-{step}\": {\n",
    "                f\"_pytorch_bce/frank-wolfe-macro-{macro_type}_k={{}}_s={{}}_t=0.0_r=0.0\": f\"Macro-{macro_type_label}\" + \"$_{\\\\mathrm{FW}}$\",\n",
    "                #f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.999-step={step}_k={k}_s=21_t=0.0_r=0.0\": None,\n",
    "                #f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.995-step={step}_k={k}_s=21_t=0.0_r=0.0\": None,\n",
    "                #f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.99-step={step}_k={k}_s=21_t=0.0_r=0.0\": None,\n",
    "                #f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.95-step={step}_k={k}_s=21_t=0.0_r=0.0\": None,\n",
    "                #f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.9-step={step}_k={{}}_s={{}}_t=0.0_r=0.0\": \"$\\\\lambda=0.9$\",\n",
    "                f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.9-step={step}_k={{}}_s={{}}_t=0.0_r=0.0\": None,\n",
    "                #f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.8-step={step}_k={k}_s=21_t=0.0_r=0.0\": None,\n",
    "                #f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.7-step={step}_k={{}}_s={{}}_t=0.0_r=0.0\": \"$\\\\lambda=0.7$\",\n",
    "                f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.7-step={step}_k={{}}_s={{}}_t=0.0_r=0.0\": None,\n",
    "                #f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.6-step={step}_k={k}_s=21_t=0.0_r=0.0\": None,\n",
    "                #f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.5-step={step}_k={{}}_s={{}}_t=0.0_r=0.0\": \"$\\\\lambda=0.5$\",\n",
    "                f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.5-step={step}_k={{}}_s={{}}_t=0.0_r=0.0\": None,\n",
    "                #f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.4-step={step}_k={k}_s=21_t=0.0_r=0.0\": None,\n",
    "                #f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.3-step={step}_k={{}}_s={{}}_t=0.0_r=0.0\": \"$\\\\lambda=0.3$\",\n",
    "                f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.3-step={step}_k={{}}_s={{}}_t=0.0_r=0.0\": None,\n",
    "                #f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.2-step={step}_k={k}_s=21_t=0.0_r=0.0\": None,\n",
    "                #f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.1-step={step}_k={{}}_s={{}}_t=0.0_r=0.0\": \"$\\\\lambda=0.1$\",\n",
    "                f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.1-step={step}_k={{}}_s={{}}_t=0.0_r=0.0\": None,\n",
    "                #f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.05-step={step}_k={k}_s=21_t=0.0_r=0.0\": None,\n",
    "                #f\"_pytorch_bce/frank-wolfe-mixed-prec-{macro_type}-alpha=0.01-step={step}_k={k}_s=21_t=0.0_r=0.0\": None,\n",
    "                f\"_pytorch_bce/fw-split-optimal-instance-prec_k={k}_s=21_t=0.0_r=0.0\": \"Top-K\",\n",
    "            },\n",
    "            \"log\": {f\"_pytorch_bce/fw-split-log_k={{}}_s={{}}_t=0.0_r=0.0\": \"Log-K\"},\n",
    "        }\n",
    "\n",
    "        for dataset, title in dataset_names.items():            \n",
    "            plot_results(f\"{directory}/{dataset}\", methods, x_axis, y_axis, k, seeds, x_axis_label, y_axis_label, title)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "]="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
