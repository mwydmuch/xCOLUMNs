{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(Path.cwd()))\n",
    "from src.frank_wolfe import (\n",
    "    frank_wolfe, \n",
    "    select_top_k_np, \n",
    "    calculate_confusion_matrix_np, \n",
    "    macro_sqrt_tp_C,\n",
    "    macro_jaccard_C, \n",
    "    macro_precision_C,\n",
    "    macro_f1_C,\n",
    "    macro_recall_C,\n",
    "    precision_at_k_C,\n",
    ")\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Definitions of some useful functions\n",
    "def fw_output_to_sampling_proba(dist, classifiers, classifiers_weights, k):\n",
    "    sampling_proba = []\n",
    "    for i in range(dist.shape[0]):\n",
    "        etas = dist[i]\n",
    "        y = np.zeros((len(classifiers), len(etas)))\n",
    "        for j in range(len(classifiers)):\n",
    "            top_k = select_top_k_np(etas, classifiers[j], k)\n",
    "            y[j,top_k] = classifiers_weights[j]\n",
    "        y = y.sum(axis=0)\n",
    "        sampling_proba.append(y)\n",
    "    return np.array(sampling_proba)\n",
    "\n",
    "\n",
    "def get_solution_using_fw(dist, k, utility_func):\n",
    "    output = frank_wolfe(dist, \n",
    "                         dist, \n",
    "                         utility_func, \n",
    "                         max_iters=1000, \n",
    "                         k=k,\n",
    "                         alpha_search_step = 0.0001, # step size for alpha search\n",
    "                         use_best_alpha=False, # use best alpha for each iteration instead of the 2 / (i + 1) rule\n",
    "                         verbose=False # print the utility value, classfiers and alpha at each iteration\n",
    "                        )\n",
    "    classifiers, classifiers_weights, meta = output\n",
    "    sampling_proba = fw_output_to_sampling_proba(dist, classifiers, classifiers_weights, k=k)\n",
    "    return sampling_proba\n",
    "\n",
    "\n",
    "def evaluate_sampling_proba(sampling_proba, dist, utility_func):\n",
    "    C = calculate_confusion_matrix_np(dist, sampling_proba, (len(dist[0]), 3))\n",
    "    return utility_func(C).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two disitrubtions to compare\n",
    "# eta of 1, 2, and 3 label for each instance\n",
    "dist1 = [\n",
    "    [0.4, 0.2, 0.6],\n",
    "    [0.8, 0.4, 0.4]\n",
    "]\n",
    "\n",
    "dist2 = [\n",
    "    [0.4, 0.2, 0.6],\n",
    "    [0.8, 0.4, 0.8]\n",
    "]\n",
    "\n",
    "dist1 = np.array(dist1)\n",
    "dist2 = np.array(dist2)\n",
    "\n",
    "# in (macro_sqrt_tp_C, macro_jaccard_C, macro_precision_C, macro_f1_C, macro_recall_C, precision_at_k_C)\n",
    "utility_func = macro_f1_C\n",
    "\n",
    "\n",
    "sol1 = get_solution_using_fw(dist1, 2, utility_func)\n",
    "sol2 = get_solution_using_fw(dist2, 2, utility_func)\n",
    "\n",
    "print(f\"solution 1:\\n{sol1}\\nutility: {evaluate_sampling_proba(sol1, dist1, utility_func)}\")\n",
    "print(f\"solution 2:\\n{sol2}\\nutility: {evaluate_sampling_proba(sol2, dist2, utility_func)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better solution for macro_f1_C (found using Bayseian optimization)\n",
    "sol3 = np.array([[1, 0, 1], [0.76810359, 0.69829113, 0.53360528]])\n",
    "print(f\"solution 3:\\n{sol3}\\nutility: {evaluate_sampling_proba(sol3, dist2, macro_f1_C)}\")\n",
    "#0.6046468639156677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import comb\n",
    "\n",
    "# Generate all possible sampling distributions for a single instance (combinations) (BFS-style algo.)\n",
    "def combinations_bfs(m, k, solution, step, array=[], sum=0):\n",
    "    if len(array) > m or sum > k: \n",
    "        return\n",
    "    if sum == k:\n",
    "        solution.append(array + [0 for _ in range(m - len(array))])\n",
    "        return\n",
    "    for i in np.arange(0, 1 + step, step):\n",
    "        combinations_bfs(m, k, solution, step, array + [i], sum + i)\n",
    "\n",
    "def combinations(m, k, step=0.01):\n",
    "    solution = []\n",
    "    combinations_bfs(m, k, solution, step=step)\n",
    "    return solution\n",
    "\n",
    "def grid_search(dist, utility_func, k, step_size=0.01):\n",
    "    sol = [(0, None)]\n",
    "    sampling_prob_comb = combinations(len(dist[0]), k, step=step_size)\n",
    "    for y_comb in tqdm(itertools.combinations_with_replacement(sampling_prob_comb, len(dist)), total=comb(len(sampling_prob_comb), len(dist))):\n",
    "        for y_perm in itertools.permutations(y_comb):\n",
    "            utility = evaluate_sampling_proba(np.array(y_perm), dist, utility_func)\n",
    "            if utility > sol[0][0]:\n",
    "                sol = [(utility, y_perm)]\n",
    "                print(f\"new best: {sol}\")\n",
    "            elif utility == sol[0][0]:\n",
    "                sol.append((utility, y_perm))\n",
    "                print(f\"new best: {sol}\")\n",
    "    return sol\n",
    "\n",
    "# This will take a few minutes to run\n",
    "gs_sol1 = grid_search(dist1, utility_func, k=2)\n",
    "gs_sol2 = grid_search(dist2, utility_func, k=2)\n",
    "gs_sol1, gs_sol2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Bounded region of parameter space\n",
    "k = 2\n",
    "pbounds = {f'y{i}': (0.000001, 1) for i in range(6)}\n",
    "\n",
    "\n",
    "def bo_sampling_proba(y0, y1, y2, y3, y4, y5):\n",
    "    y = np.array([y0, y1, y2, y3, y4, y5])\n",
    "    y = y.reshape((2, 3))\n",
    "    if y[0].sum() < 2 or y[1].sum() < 2:\n",
    "        return 0\n",
    "    y[0] = y[0] / y[0].sum() * k\n",
    "    y[1] = y[1] / y[1].sum() * k\n",
    "    return y\n",
    "\n",
    "\n",
    "def bo_utility_func(y0, y1, y2, y3, y4, y5):\n",
    "    y = bo_sampling_proba(y0, y1, y2, y3, y4, y5)\n",
    "    return evaluate_sampling_proba(y, dist2, utility_func)\n",
    "\n",
    "\n",
    "optimizer = BayesianOptimization(f=bo_utility_func, pbounds=pbounds, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun this function if you want it to do more iterations\n",
    "optimizer.maximize(init_points=200, n_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_params = max(optimizer.res, key=lambda x: x['target'])\n",
    "sol = bo_sampling_proba(**max_params['params'])\n",
    "sol, evaluate_sampling_proba(sol, dist2, utility_func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
